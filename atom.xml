<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id></id>
    <title>Matthew Daly&apos;s Blog</title>
    <updated>2018-12-27T16:01:37Z</updated>
    <generator>grunt-blogbuilder https://github.com/matthewbdaly/grunt-blogbuilder</generator>
    <author>
        <name>Matthew Daly</name>
        <email>matthew@matthewdaly.co.uk</email>
        <uri>https://matthewdaly.co.uk</uri>
    </author>
    <link rel="alternate" href="https://matthewdaly.co.uk"/>
    <subtitle>I&apos;m a web developer in Norfolk. This is my blog...</subtitle>
    <rights>Matthew Daly 2018</rights>
    <entry>
        <title type="html"><![CDATA[Decorating service classes]]></title>
        <id>https://matthewdaly.co.uk/blog/2018/12/06/decorating-service-classes/</id>
        <link href="https://matthewdaly.co.uk/blog/2018/12/06/decorating-service-classes/">
        </link>
        <updated>2018-12-06T18:34:16Z</updated>
        <summary type="html"><![CDATA[<p>I’ve written before about using decorators to extend the functionality of existing classes, in the context of the repository pattern when working with Eloquent. However, the same practice is applicable in many other contexts.</p>
<p>Recently, I was asked to add RSS feeds to the home page of the legacy project that is my main focus these days. The resulting service class looked something like this:</p>
<pre><code class="lang-php">&lt;?php

namespace App\Services;

use Rss\Feed\Reader;
use App\Contracts\Services\FeedFetcher;

class RssFetcher implements FeedFetcher
{
    public function fetch($url)
    {
        return Reader::import($url);
    }
}
</code></pre>
<p>In accordance with the principle of loose coupling, I also created an interface for it:</p>
<pre><code class="lang-php">&lt;?php

namespace App\Contracts\Services;

interface FeedFetcher
{
    public function fetch($url);
}
</code></pre>
<p>I was recently able to add dependency injection to the project using PHP-DI, so now I can inject an instance of the feed fetcher into the controller by typehinting the interface and having it resolve to the <code>RssFetcher</code> class.</p>
<p>However, there was an issue. I didn’t want the application to make multiple HTTP requests to fetch those feeds every time the page loads. At the same time, it was also a bit much to have a scheduled task running to fetch those feeds and store them in the database, since many times that would be unnecessary. The obvious solution was to cache the feed content for a specified length of time, in this case five minutes.</p>
<p>I <em>could</em> have integrated the caching into the service class itself, but that wasn’t the best practice, because it would be tied to that implementation. If in future we needed to switch to a different feed handler, we’d have to re-implement the caching functionality. So I decided it made sense to decorate the service class.</p>
<p>The decorator class implemented the same interface as the feed fetcher, and accepted another instance of that interface in the constructor, along with a PSR6-compliant caching library. It looked something like this:</p>
<pre><code class="lang-php">&lt;?php

namespace App\Services;

use App\Contracts\Services\FeedFetcher;
use Psr\Cache\CacheItemPoolInterface;

class FetcherCachingDecorator implements FeedFetcher
{
    protected $fetcher;

    protected $cache;

    public function __construct(FeedFetcher $fetcher, CacheItemPoolInterface $cache)
    {
        $this-&gt;fetcher = $fetcher;
        $this-&gt;cache = $cache;
    }

    public function fetch($url)
    {
        $item = $this-&gt;cache-&gt;getItem(&#39;feed_&#39;.$url);
        if (!$item-&gt;isHit()) {
            $item-&gt;set($this-&gt;fetcher-&gt;fetch($url));
            $this-&gt;cache-&gt;save($item);
        }
        return $item-&gt;get();
    }
}
</code></pre>
<p>Now, when you instantiate the feed fetcher, you wrap it in the decorator as follows:</p>
<pre><code class="lang-php">&lt;?php

$fetcher = new FetcherCachingDecorator(
        new App\Services\RssFetcher,
        $cache
);
</code></pre>
<p>As you can see, this solves our problem quite nicely. By wrapping our feed fetcher in this decorator, we keep the caching layer completely separate from any one implementation of the fetcher, so in the event we need to swap the current one out for another implementation, we don’t have to touch the caching layer at all. As long as we’re using dependency injection to resolve this interface, we’re only looking at a little more code to instantiate it.</p>
<p>In addition, this same approach can be applied for other purposes, and you can wrap the service class as many times as necessary. For instance, if we wanted to log all the responses we got, we could write a logging decorator something like this:</p>
<pre><code class="lang-php">&lt;?php

namespace App\Services;

use App\Contracts\Services\FeedFetcher;
use Psr\Log\LoggerInterface;

class FeedLoggingDecorator implements FeedFetcher
{
    protected $fetcher;

    protected $logger;

    public function __construct(FeedFetcher $fetcher, LoggerInterface $logger)
    {
        $this-&gt;fetcher = $fetcher;
        $this-&gt;logger = $logger;
    }

    public function fetch($url)
    {
        $response = $this-&gt;fetcher-&gt;fetch($url);
        $this-&gt;logger-&gt;info($response);
        return $response;
    }
}
</code></pre>
<p>The same idea can be applied to an API client. For instance, say we have the following interface for an API client:</p>
<pre><code class="lang-php">&lt;?php

namespace Foo\Bar\Contracts;

use Foo\Bar\Objects\Item;
use Foo\Bar\Objects\ItemCollection;

interface Client
{
    public function getAll(): ItemCollection;

    public function find(int $id): Item;

    public function create(array $data): Item;

    public function update(int $id, array $data): Item;

    public function delete(int $id);
}
</code></pre>
<p>Now, of course any good API client should respect HTTP headers and use those to do some caching itself, but depending on the use case, you may also want to cache these requests yourself. For instance, if the only changes to the entities stored by the third party API will be ones you’ve made, or they don’t need to be 100% up to date, you may be better off caching those responses before they reach the actual API client. Under those circumstances, you might write a decorator like this to do the caching:</p>
<pre><code class="lang-php">&lt;?php

namespace Foo\Bar\Services;

use Foo\Bar\Contracts\Client;
use Psr\Cache\CacheItemPoolInterface;

class CachingDecorator implements Client
{
    protected $client;

    protected $cache;

    public function __construct(Client $client, CacheItemPoolInterface $cache)
    {
        $this-&gt;client = $client;
        $this-&gt;cache = $cache;
    }

    public function getAll(): ItemCollection
    {
        $item = $this-&gt;cache-&gt;getItem(&#39;item_all&#39;);
        if (!$item-&gt;isHit()) {
            $item-&gt;set($this-&gt;client-&gt;getAll());
            $this-&gt;cache-&gt;save($item);
        }
        return $item-&gt;get();
    }

    public function find(int $id): Item
    {
        $item = $this-&gt;cache-&gt;getItem(&#39;item_&#39;.$id);
        if (!$item-&gt;isHit()) {
            $item-&gt;set($this-&gt;client-&gt;find($id));
            $this-&gt;cache-&gt;save($item);
        }
        return $item-&gt;get();

    }

    public function create(array $data): Item
    {
        $this-&gt;cache-&gt;clear();
        return $this-&gt;client-&gt;create($data);
    }

    public function update(int $id, array $data): Item
    {
        $this-&gt;cache-&gt;clear();
        return $this-&gt;client-&gt;update($id, $data);
    }

    public function delete(int $id)
    {
        $this-&gt;cache-&gt;clear();
        return $this-&gt;client-&gt;delete($id);
    }
}
</code></pre>
<p>Any methods that change the state of the data on the remote API will clear the cache, while any that fetch data will first check the cache, only explicitly fetching data from the API when the cache is empty, and caching it again. I won’t go into how you might write a logging decorator for this, but it should be straightforward to figure out for yourself.</p>
<p>The decorator pattern is a very powerful way of adding functionality to a class without tying it to a specific implementation. If you’re familiar with how middleware works, decorators work in a very similar fashion in that you can wrap your service in as many layers as you wish in order to accomplish specific tasks, and they adhere to the single responsibility principle by allowing you to use different decorators for different tasks.</p>
]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Simplify your tests with anonymous classes]]></title>
        <id>https://matthewdaly.co.uk/blog/2018/10/20/simplify-your-tests-with-anonymous-classes/</id>
        <link href="https://matthewdaly.co.uk/blog/2018/10/20/simplify-your-tests-with-anonymous-classes/">
        </link>
        <updated>2018-10-20T13:48:05Z</updated>
        <summary type="html"><![CDATA[<p>Anonymous classes were added in PHP7, but so far I haven’t made all that much use of them. However, recently I’ve been working on building a simple dependency injection container for learning purposes. This uses the PHP Reflection API to determine how to resolve dependencies. For instance, if it’s asked for a class for which one of the dependencies required by the constructor is an instance of the <code>DateTime</code> class, it should create an instance, and then pass it into the constructor automatically when instantiating the class. Then it should return the newly created class.</p>
<p>Mocking isn’t really a suitable approach for this use case because the container needs to return a concrete class instance to do its job properly. You could just create a series of fixture classes purely for testing purposes, but that would mean either defining more than one class in a file (violating PSR-2), or defining a load of fixture classes in separate files, meaning you’d have to write a lot of boilerplate, and you’d have to move between several different files to understand what’s going on in the test.</p>
<p>Anonymous classes allow you a means to write simple classes for tests inline, as in this example for retrieving a very basic class. The tests use PHPSpec:</p>
<pre><code class="lang-php7">&lt;?php

namespace spec\Vendor\Package;

use Vendor\Package\MyClass;
use PhpSpec\ObjectBehavior;
use Prophecy\Argument;
use DateTime;

class MyClassSpec extends ObjectBehavior
{
    function it_can_resolve_registered_dependencies()
    {
        $toResolve = new class {
        };
        $this-&gt;set(&#39;Foo\Bar&#39;, $toResolve);
        $this-&gt;get(&#39;Foo\Bar&#39;)-&gt;shouldReturnAnInstanceOf($toResolve);
    }
}
</code></pre>
<p>You can also define your own methods inline. Here we implement the <code>invoke()</code> magic method so that the class is a callable:</p>
<pre><code class="lang-php7">&lt;?php

class MyClassSpec extends ObjectBehavior
{
    function it_can_resolve_registered_invokable()
    {
        $toResolve = new class {
            public function __invoke() {
                return new DateTime;
            }
        };
        $this-&gt;set(&#39;Foo\Bar&#39;, $toResolve);
        $this-&gt;get(&#39;Foo\Bar&#39;)-&gt;shouldReturnAnInstanceOf(&#39;DateTime&#39;);
    }
}
</code></pre>
<p>You can also define a constructor. Here, we’re getting the class name of a newly created anonymous class that accepts an instance of <code>DateTime</code> as an argument to the constructor. Then, we can resolve a new instance out of the container:</p>
<pre><code class="lang-php7">&lt;?php

class MyClassSpec extends ObjectBehavior
{
    function it_can_resolve_dependencies()
    {
        $toResolve = get_class(new class(new DateTime) {
            public $datetime;
            public function __construct(DateTime $datetime)
            {
                $this-&gt;datetime = $datetime;
            }
        });
        $this-&gt;set(&#39;Foo\Bar&#39;, $toResolve);
        $this-&gt;get(&#39;Foo\Bar&#39;)-&gt;shouldReturnAnInstanceOf($toResolve);
    }
}
</code></pre>
<p>For classes that will extend an existing class or implement an interface, you can define those inline too. Or you can include a trait:</p>
<pre><code class="lang-php7">&lt;?php

class MyClassSpec extends ObjectBehavior
{
    function it_can_resolve_dependencies()
    {
        $toResolve = get_class(new class(new DateTime) extends Foo implements Bar {
            public $datetime;
            public function __construct(DateTime $datetime)
            {
                $this-&gt;datetime = $datetime;
            }

            use MyTrait;
        });
        $this-&gt;set(&#39;Foo\Bar&#39;, $toResolve);
        $this-&gt;get(&#39;Foo\Bar&#39;)-&gt;shouldReturnAnInstanceOf($toResolve);
    }
}
</code></pre>
<p>In cases where the functionality is contained in a trait or abstract class, and you might need to add little or no additional functionality, this is a lot less verbose than creating a class the conventional way.</p>
<p>None of this is stuff you can’t do without anonymous classes, but by defining these sort of disposable fixture classes inline in your tests, you’re writing the minimum amount of code necessary to implement your test, and it’s logical to define it inline since it’s only ever used in the tests. One thing to bear in mind is that anonymous classes are created and instantiated at the same time, so you can’t easily create a class and then instantiate an instance of it separately. However, you can instantiate one, then use the <code>get_class()</code> function to get its class name and use that to resolve it, which worked well for my use case.</p>
<p>Another use case for anonymous classes is testing traits or abstract classes. I generally use Mockery as my mocking solution with PHPUnit tests, but I’ve sometimes missed the <code>getMockForTrait()</code> method from PHPUnit. However, another option is to instantiate an anonymous class that includes that trait for testing purposes:</p>
<pre><code class="lang-php7">&lt;?php

$item = new class() {
    use MyTrait;
};
</code></pre>
<p>This way, your test class is as minimal as possible, and you can test the trait/abstract class in a fairly isolated fashion.</p>
]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adding React to a legacy project]]></title>
        <id>https://matthewdaly.co.uk/blog/2018/10/16/adding-react-to-a-legacy-project/</id>
        <link href="https://matthewdaly.co.uk/blog/2018/10/16/adding-react-to-a-legacy-project/">
        </link>
        <updated>2018-10-16T08:00:29Z</updated>
        <summary type="html"><![CDATA[<p>The project I’m currently working on is a textbook example of what happens when a project uses jQuery when it really ought to use a proper Javascript framework, or it starts out just using jQuery and grows out of all proportion. It’s also not helped by the fact that historically it’s just been worked on when new functionality needs to be added, meaning that rather than refactoring the code base, it’s been copied-and-pasted. As a result, there’s lots of repetitive code in desparate need of refactoring, and huge reams of horrible jQuery spaghetti code.</p>
<p>When I first took over responsibility for the project, I integrated Laravel Mix into it so that I had the means to refactor some of the common functionality into separate files and require them during the build process, as well as use ES6. However, this was only the first step, as it didn’t sort out the fundamental problem of repetitive boilerplate code being copied and pasted. What I needed was a refactor to use something more opinionated. As it happened, I was asked to add a couple of modals to the admin, and since the modals were one of the worst parts of the admin in terms of repetitive code, they were a strong candidate for implementing using a more suitable library.</p>
<p>I looked at a few options:</p>
<ul>
<li>I’ve used Angular 1 quite successfully in the past, but I didn’t really want to use a framework that was being killed off, and it would be difficult to retrofit into a legacy application</li>
<li>Angular 2+ is actively maintained, but it would again be difficult to retrofit it into a legacy application. In addition, the need for TypeScript would make it problematic.</li>
<li>Vue was a possibility, but it did a bit too much for this use case, and it wasn’t all that clear how to retrofit it to an existing application</li>
</ul>
<p>Eventually, I settled on React.js, for the following reasons:</p>
<ul>
<li>It has a preset in Laravel Mix, making it easy to get started with it.</li>
<li>It has a very limited target - React is closely focused on the view layer, dealing only with rendering and event handling, so it does just what I needed in this case.</li>
<li>It has a strong record of use with legacy applications - after all, it was created by Facebook and they added it incrementally.</li>
<li>It’s easy to test - Jest’s snapshot tests make it easy to verify the rendered content hasn’t changed, and using Enzyme it’s straightforward to test interactions with the component</li>
<li>Higher order components provide a straightforward way to share functionality between components, which I needed to allow different modals to deal with another modal in the same way.</li>
<li>By creating a series of components for common user interface elements, I could then re-use those components in future work, saving time and effort.</li>
</ul>
<p>However, it wasn’t entirely clear how I might go about integrating React into a legacy application. In the end, I managed to figure out an approach which worked.</p>
<p>Normally, I would create a single root for my application, something like this:</p>
<pre><code class="lang-javascript">import React from &#39;react&#39;;
import ReactDOM from &#39;react-dom&#39;;
import App from &#39;./components/App&#39;;

ReactDOM.render(
    &lt;App /&gt;,
    document.getElementById(&#39;root&#39;)
);
</code></pre>
<p>However, that wasn’t an option here. The existing modals were using jQuery and Bootstrap, and the new modals had to work with them. I therefore needed to have only certain parts of the UI managed with React, and the rest wouldn’t be touched. Here’s an example of how I rendered the modal in the end:</p>
<pre><code class="lang-javascript">import React from &#39;react&#39;;
import ReactDOM from &#39;react-dom&#39;;
import higherOrderComponent from &#39;./components/higherOrderComponent&#39;;
import modalComponent from &#39;./components/modalComponent&#39;;

const Modal = higherOrderComponent(modalComponent);
window.componentWrapper = ReactDOM.render(
  &lt;Modal /&gt;,
  document.getElementById(&#39;modalTarget&#39;)
);

window.componentWrapper.setState({
  foo: &#39;bar&#39;
});
</code></pre>
<p>By extracting the duplicate functionality into a higher order component, I could easily wrap the new modals in that component and share that functionality between the modals. I could then render each component in a different target element, and assign it to a variable in the <code>window</code> namespace. The div with a ID of <code>modalTarget</code> needed to be added in the appropriate place, but otherwise the HTML didn’t need to be touched, since the required markup was in the React component instead.</p>
<p>Then, when I needed to change a value int the statee of the component, I could just call <code>window.componentWrapper.setState({})</code>, passing through the values to set, and these would propogate down to the child components as usual. I could also render multiple different modal components on the page, and refer to each one separately in order to set the state.</p>
<p>This isn’t an approach I’d recommend on a greenfield project - state isn’t really something you should be setting from outside a component like this, and normally I wouldn’t do it. However, it seemed to be the easiest way for this particular use case. Over time I’ll port more and more of the UI over to React, and eventually it won’t be necessary as I’ll be storing the application state in something like Redux.</p>
]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Do you still need jQuery?]]></title>
        <id>https://matthewdaly.co.uk/blog/2018/10/11/do-you-still-need-jquery/</id>
        <link href="https://matthewdaly.co.uk/blog/2018/10/11/do-you-still-need-jquery/">
        </link>
        <updated>2018-10-11T08:21:58Z</updated>
        <summary type="html"><![CDATA[<p>There was a time not so long ago when jQuery was ubiquitous. It was used on almost every website as a matter of course, to the point that many HTML boilerplates included a reference to the CDN.</p>
<p>However, more and more I think it’s probably unnecessary for two main use cases:</p>
<h2 id="jquery-is-probably-unnecessary-for-many-web-apps-with-simple-javascript">jQuery is probably unnecessary for many web apps with simple Javascript</h2>
<p>When jQuery first appeared, IE6 was commonplace, and browser API’s were notoriously inconsistent. jQuery was very useful in ironing out those inconsistencies and helping to make the developer’s experience a bit better.</p>
<p>Nowadays, that’s no longer the case. Internet Explorer is on its way out, with IE11 being the only version still supported by Microsoft, and it’s becoming increasingly hard to justify support for older versions, especially with mobile browsers forming a bigger than ever chunk of the market. We’ll probably need to continue supporting IE11 for a good long while, and possibly IE10 for some time too, but these aren’t anything like as bad to work with as IE6. It’s worth noting that newer versions of jQuery are also dropping support for these older browsers, so in many ways it actually does less than it used to.</p>
<p><a href="http://lmgtfy.com/?q=do+you+still+need+jquery">This is the usual thrust of articles on whether you should still be using jQuery</a> so I’m not going to go over this matter , but for many smaller web apps, jQuery is no longer necessary, and a lot of developers have a tendency to keep using it when it’s probably not required.</p>
<h2 id="jquery-is-insufficient-for-web-apps-with-complex-javascript">jQuery is insufficient for web apps with complex Javascript</h2>
<p>Nowadays, there’s a lot of web applications that have moved big chunks of functionality from the server side to the client side. Beyond a certain (and quite small) level of complexity, jQuery just doesn’t do enough to cut it. For me personally, the nature of the projects I work on means that this is a far, far bigger issue than the first one.</p>
<p>I used to work predominantly with Phonegap, which meant that a lot of functionality traditionally done on the server side had to be moved to the client side, and for that jQuery was never sufficient. My first Phonegap app started out using jQuery, but it quickly became obvious that it was going to be problematic. It wound up as a huge mass of jQuery callbacks and Handlebars templates, which was almost impossible to test and hard to maintain. Given this experience, I resolved to switch to a full-fledged Javascript framework next time I built a mobile app, and for the next one I chose Backbone.js, which still used jQuery as a dependency, but made things more maintainable by giving a structure that it didn’t have before, which was the crucial difference.</p>
<p>The more modern generation of Javascript frameworks such as Vue and React, go further in making jQuery redundant. Both of these implement a so-called Virtual DOM, which is used to calculate the minimum changes required to re-render the element in question. Subsequently using jQuery to mutate the DOM would cause problems because it would get out of sync with the Virtual DOM - in fact, in order to get a jQuery plugin working in the context of a React component, you have to actively prevent React from touching the DOM, thereby losing most of the benefits of using React in the first place. You usually see better results from using a React component designed for that purpose (or writing one, which React makes surprisingly simple), than from trying to shoehorn a jQuery plugin into it.</p>
<p>They also make a lot of things that jQuery does trivially easy - for instance, if you want to conditionally show and hide content in a React component, it’s just a case of building it to hide that content based on a particular value in the props or state, or filtering a list is just a case of applying a filter to the array containing the data and setting the state as appropriate.</p>
<p>In short, for single-page web apps or other ones with a lot of Javascript, you should look at other solutions first, and not just blithely assume jQuery will be up to the task. It’s technically possible to build this sort of web app using jQuery, but it’s apt to turn into a morass of spaghetti code unless approached with a great deal of discipline, one that sadly many developers don’t have, and it doesn’t exactly make it easy to promote code reuse. These days, I prefer React for complex web apps, because it makes it extremely intuitive to break my user interface up into reusable components, and test them individually. Using React would be overkill on brochure-style sites (unless you wanted to build it with something like Gatsby), but for more complex apps it’s often a better fit than jQuery.</p>
<h2 id="so-when-should-you-use-jquery-">So when should you use jQuery?</h2>
<p>In truth, I’m finding it harder and harder to justify using it at all on new builds. I use it on my personal site because that’s built on Bootstrap 3 and so depends on jQuery, but for bigger web apps I’m generally finding myself moving to React, which renders it not just unnecessary for DOM manipulation, but counter-productive to use it. Most of what I do is big enough to justify something like React, and it generally results in code that is more declarative, easier to test and reason about, and less repetitive. Using jQuery for an application like this is probably a bad idea, because it’s difficult (not impossible, mind, if you follow some of the advice <a href="https://learn.jquery.com/code-organization/">here</a>, use a linter and consider using a proper client-side templating system alongside jQuery) to build an elegant and maintainable Javascript-heavy application.</p>
<p>As a rule of thumb, I find anything which is likely to require more than a few hundred lines of Javascript to be written, is probably complex enough that jQuery isn’t sufficient, and I should instead consider something like React.</p>
<p>I doubt it’d be worth the bother of ripping jQuery out of a legacy application and rewriting the whole thing to not require it, but for new builds I would think very hard about:</p>
<ul>
<li>Whether jQuery is sufficient, or you’d be better off using something like React, Vue or Angular</li>
<li>If it is sufficient, whether it’s actually necessary</li>
</ul>
<p>In all honesty, I don’t think using it when it’s technically not necessary is as much of a big deal as the issue of using it when it’s not really sufficient. Yes, dowloading a library you technically don’t need for a page is a bad practice, and it does make your site slower and harder for users on slow mobile connections, but there are ways to mitigate that such as CDN’s, caching and minification. If you build a web app using jQuery alone when React, Vue or Angular would be more suitable, you’re probably going to have to write a lot more code that will be difficult to maintain, test and understand. Things like React were created to solve the problems that arose when developers built complex client-side applications with jQuery, and are therefore a good fit for bigger applications. The complex setup does mean they have a threshold below which it’s not worth the bother of using them, but past that threshold they result in better, more maintainable, more testable and more reusable code.</p>
<h2 id="now-react-is-cool-you-hate-jquery-you-hipster-">Now React is cool, you hate jQuery, you hipster…</h2>
<p>Don’t be a prat. Bitter experience has taught me that for a lot of my own personal use cases, jQuery is insufficient. It doesn’t suck, it’s just insufficient. If for your use case, jQuery <em>is</em> sufficient, then that’s fine. All I’m saying is that when a web app becomes sufficiently complex, jQuery can begin to cause more problems than it solves, and that for a sufficiently complex web app you should consider other solutions.</p>
<p>I currently maintain a legacy application that includes thousands of lines of Javascript. Most of it is done with jQuery and some plugins, and it’s resulted in some extremely repetitive jQuery callbacks that are hard to maintain and understand, and impossible to test. Recently I was asked to add a couple of modals to the admin interface, and rather than continuing to add them using jQuery and adding more spaghetti code, I instead opted to build them with React. During the process of building the first modal, I produced a number of components for different elements of the UI. Then, when I built the second one, I refactored those components to be more generic, and moved some common functionality into a higher-order component so that it could be reused. Now, if I need to add another modal, it will be trivial because I already have those components available, and I can just create a new component for the modal, import those components that I need, wrap it in the higher-order component if necessary, and that’s all. I can also easily test those components in isolation. In short, I’ve saved myself some work in the long run by writing it to use a library that was a better fit.</p>
<p>It’s not like using jQuery inevitably results in unmaintainable code, but it does require a certain amount of discipline to avoid it. A more opinionated library such as React makes it far, far harder to create spaghetti code, and makes code reuse natural in a way that jQuery doesn’t.</p>
]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[An approach to writing golden master tests for PHP web applications]]></title>
        <id>https://matthewdaly.co.uk/blog/2018/10/08/an-approach-to-writing-golden-master-tests-for-php-web-applications/</id>
        <link href="https://matthewdaly.co.uk/blog/2018/10/08/an-approach-to-writing-golden-master-tests-for-php-web-applications/">
        </link>
        <updated>2018-10-08T10:20:53Z</updated>
        <summary type="html"><![CDATA[<p>Apologies if some of the spelling or formatting on this post is off - I wrote it on a long train journey down to London, with sunlight at an inconvenient angle.</p>
<p>Recently I had to carry out some substantial changes to the legacy web app I maintain as the lion’s share of my current job. The client has several channels that represent different parts of the business that would expect to see different content on the home page, and access to content is limited first by channel, and then by location. The client wanted an additional channel added. Due to bad design earlier in the application’s lifetime that isn’t yet practical to refactor away, each type of location has its own model, so it was necessary to add a new location model. It also had to work seamlessly, in the same way as the other location types. Unfortunately, these branch types didn’t use polymorphism, and instead used large switch statements, and it wasn’t practical to refactor all that away in one go. This was therefore quite a high-risk job, especially considering the paucity of tests on a legacy code base.</p>
<p>I’d heard of the concept of a <em>golden master test</em> before. If you haven’t heard of it before, the idea is that it works by running a process, capturing the output, and then comparing the output of that known good version against future runs. It’s very much a test of last resort since, in the context of a web app, it’s potentially very brittle since it depends on the state of the application remaining the same between runs to avoid false positives. I needed a set of simple “snapshot tests”, similar to how snapshot testing works with Jest, to catch unexpected breakages in a large number of pages, and this approach seemed to fit the bill. Unfortunately, I hadn’t been able to find a good example of how to do this for PHP applications, so it took a while to figure out something that worked.</p>
<p>Here is an example base test case I used for this approach:</p>
<pre><code class="lang-php">&lt;?php

namespace Tests;

use PHPUnit_Framework_TestCase as BaseTestCase;
use Behat\Mink\Driver\GoutteDriver;
use Behat\Mink\Session;

class GoldenMasterTestCase extends BaseTestCase
{
    protected $driver;

    protected $session;

    protected $baseUrl = &#39;http://localhost:8000&#39;;

    protected $snapshotDir = &quot;tests/snapshots/&quot;;

    public function setUp()
    {
        $this-&gt;driver = new GoutteDriver();
        $this-&gt;session = new Session($this-&gt;driver);
    }

    public function tearDown()
    {
        $this-&gt;session = null;
        $this-&gt;driver = null;
    }

    public function loginAs($username, $password)
    {
        $this-&gt;session-&gt;visit($this-&gt;baseUrl.&#39;/login&#39;);
        $page = $this-&gt;session-&gt;getPage();
        $page-&gt;fillField(&quot;username&quot;, $username);
        $page-&gt;fillField(&quot;password&quot;, $password);
        $page-&gt;pressButton(&quot;Sign In&quot;);
        return $this;
    }

    public function goto($path)
    {
        $this-&gt;session-&gt;visit($this-&gt;baseUrl.$path);
        $this-&gt;assertNotEquals(404, $this-&gt;session-&gt;getStatusCode());
        return $this;
    }

    public function saveHtml()
    {
        if (!$this-&gt;snapshotExists()) {
            $this-&gt;saveSnapshot();
        }
        return $this;
    }

    public function assertSnapshotsMatch()
    {
        $path = $this-&gt;getPath();
        $newHtml = $this-&gt;processHtml($this-&gt;getHtml());
        $oldHtml = $this-&gt;getOldHtml();
        $diff = &quot;&quot;;
        if (function_exists(&#39;xdiff_string_diff&#39;)) {
            $diff = xdiff_string_diff($oldHtml, $newHtml);
        }
        $message = &quot;The path $path does not match the snapshot\n$diff&quot;;
        self::assertThat($newHtml == $oldHtml, self::isTrue(), $message);
    }

    protected function getHtml()
    {
        return $this-&gt;session-&gt;getPage()-&gt;getHtml();
    }

    protected function getPath()
    {
        $url = $this-&gt;session-&gt;getCurrentUrl();
        $path = parse_url($url, PHP_URL_PATH);
        $query = parse_url($url, PHP_URL_QUERY);
        $frag = parse_url($url, PHP_URL_FRAGMENT);
        return $path.$query.$frag;
    }

    protected function getEscapedPath()
    {
        return $this-&gt;snapshotDir.str_replace(&#39;/&#39;, &#39;_&#39;, $this-&gt;getPath()).&#39;.snap&#39;;
    }

    protected function snapshotExists()
    {
        return file_exists($this-&gt;getEscapedPath());
    }

    protected function processHtml($html)
    {
        return preg_replace(&#39;/&lt;input type=&quot;hidden&quot;[^&gt;]+\&gt;/i&#39;, &#39;&#39;, $html);
    }

    protected function saveSnapshot()
    {
        $html = $this-&gt;processHtml($this-&gt;getHtml());
        file_put_contents($this-&gt;getEscapedPath(), $html);
    }

    protected function getOldHtml()
    {
        return file_get_contents($this-&gt;getEscapedPath());
    }
}
</code></pre>
<p>Because this application is built with Zend 1 and doesn’t have an easy way to get the HTML response without actually running the application, I was forced to use an actual HTTP client to fetch the content while the web server is running. I’ve used Mink together with Behat many times in the past, and the Goutte driver is fast and doesn’t rely on Javascript, so that was the best bet for a simple way of retrieving the HTML. Had I been taking this approach with a Laravel application, I could have populated the testing database with a common set of fixtures, and passed a request object through the application and captured the response object’s output rather than using an HTTP client, thereby eliminating the need to run a web server and making the tests faster and less brittle.</p>
<p>Another issue was CSRF handling. A CSRF token is, by definition, generated randomly each time the page is loaded, and so it broke those pages that had forms with CSRF tokens. The solution I came up with was to strip out the hidden input fields.</p>
<p>When each page is tested, the first step is to fetch the content of that page. The test case then checks to see if there’s an existing snapshot. If not, the content is saved as a new snapshot file. Otherwise, the two snapshots are compared, and the test fails if they do not match.</p>
<p>Once that base test case was in place, it was then straightforward to extend it to test multiple pages. I wrote one test to check pages that did not require login, and another to check pages that did require login, and the paths for those pages were passed through using a data provider method, as shown below:</p>
<pre><code class="lang-php">&lt;?php

namespace Tests\GoldenMaster;

use Tests\GoldenMasterTestCase;

class GoldenMasterTest extends GoldenMasterTestCase
{
    /**
     * @dataProvider nonAuthDataProvider
     */
    public function testNonAuthPages($data)
    {
        $this-&gt;goto($data)
            -&gt;saveHtml()
            -&gt;assertSnapshotsMatch();
    }

    public function nonAuthDataProvider()
    {
        return [
            [&#39;/login&#39;],
        ];
    }

    /**
     * @dataProvider dataProvider
     */
    public function testPages($data)
    {
        $this-&gt;loginAs(&#39;foo&#39;, &#39;bar&#39;)
            -&gt;goto($data)
            -&gt;saveHtml()
            -&gt;assertSnapshotsMatch();
    }

    public function dataProvider()
    {
        return [
            [&#39;/foo&#39;],
            [&#39;/bar&#39;],
        ];
    }
}
</code></pre>
<p>Be warned, this is <em>not</em> an approach I would advocate as a matter of course, and it should only ever be a last resort as an alternative to onerous manual testing for things that can’t be tested in their current form. It’s extremely brittle, and I’ve had to deal with a lot of false positives, although that would be easier if I could populate a testing database beforehand and use that as the basis of the tests. It’s also very slow, with each test taking three or four seconds to run, although again this would be less of an issue if I could pass through a request object and get the response HTML directly. Nonetheless, I’ve found it to be a useful technique as a test of last resort for legacy applications.</p>
]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding the pipeline pattern]]></title>
        <id>https://matthewdaly.co.uk/blog/2018/10/05/understanding-the-pipeline-pattern/</id>
        <link href="https://matthewdaly.co.uk/blog/2018/10/05/understanding-the-pipeline-pattern/">
        </link>
        <updated>2018-10-05T18:36:16Z</updated>
        <summary type="html"><![CDATA[<p>In a previous post, I used the pipeline pattern to demonstrate processing letters using optical recognition and machine learning. The pipeline pattern is something I’ve found very useful in recent months. For a sequential series of tasks, this approach can make your code easier to understand by allowing you to break it up into simple, logical steps which are easy to test and understand individually. If you’re familiar with pipes and redirection in Unix, you’ll be aware of how you can chain together multiple, relatively simple commands to carry out some very complex transformations on data.</p>
<p>A few months back, I was asked to build a webhook for a Facebook lead form at work. One of my colleagues was having to manually export CSV data from Facebook for the data, and then import it into a MySQL database and a Campaign Monitor mailing list, which was an onerous task, so they asked me to look at more automated solutions. I wound up building a webhook with Lumen that would go through the following steps:</p>
<ul>
<li>Get the lead ID’s from the webhook</li>
<li>Pull the leads from the Facebook API using those ID’s</li>
<li>Process the raw data into a more suitable format</li>
<li>Save the data to the database</li>
<li>Push the data to Campaign Monitor</li>
</ul>
<p>Since this involved a number of discrete steps, I chose to implement each step as a separate stage. That way, each step was easy to test in isolation, and it was easily reusable. As it turned out, this approach saved us because Facebook needed to approve this app (and ended up rejecting it - their documentation at the time wasn’t clear on implementing server-to-server apps, making it hard to meet their guidelines), so we needed an interim solution. I instead wrote an Artisan task for importing the file from a CSV, which involved the following steps:</p>
<ul>
<li>Read the rows from the CSV file</li>
<li>Format the CSV data into the desired format</li>
<li>Save the data to the database</li>
<li>Push the data to Campaign Monitor</li>
</ul>
<p>This meant that two of the existing steps could be reused, as is, without touching the code or tests. I just added two new classes to read the data and format the data, and the Artisan command, which simply called the various pipeline stages, <em>and that was all</em>. In this post, I’ll demonstrate how I implemented this.</p>
<p>While there is more than one implementation of this available, and it wouldn’t be hard to roll your own, I generally use the PHP League’s <a href="https://pipeline.thephpleague.com/">Pipeline package</a>, since it’s simple, solid and well-tested. Let’s say our application has three steps:</p>
<ul>
<li>Format the request data</li>
<li>Save the data</li>
<li>Push it to a third party service.</li>
</ul>
<p>We therefore need to write a stage for each step in the process. Each one must be a callable, such as a closure, a callback, or a class that implements the <code>__invoke()</code> magic method. I usually go for the latter as it allows you to more easily inject dependencies into the stage via its constructor, making it easier to use and test. Here’s what our first stage might look like:</p>
<pre><code class="lang-php">&lt;?php

namespace App\Stages;

use Illuminate\Support\Collection;

class FormatData
{
    public function __invoke(Collection $data): Collection
    {
        return $data-&gt;map(function ($item) {
            return [
                &#39;name&#39; =&gt; $item-&gt;fullname,
                &#39;email&#39; =&gt; $item-&gt;email
            ];
        });
    }
}
</code></pre>
<p>This class does nothing more than receive a collection, and format the data as expected. We could have it accept a request object instead, but I opted not to because I felt it made more sense to pass the data in as a collection so it’s not tied to an HTTP request. That way, it can also handle data passed through from a CSV file using an Artisan task, and the details of how it receives the data in the first place are deferred to the class that calls the pipeline in the first place. Note this stage also returns a collection, for handling by the next step:</p>
<pre><code class="lang-php">&lt;?php

namespace App\Stages;

use App\Lead;
use Illuminate\Support\Collection;

class SaveData
{
    public function __invoke(Collection $data): Collection
    {
        return $data-&gt;map(function ($item) {
            $lead = new Lead;
            $lead-&gt;name = $item-&gt;name;
            $lead-&gt;email = $item-&gt;email;
            $lead-&gt;save();
            return $lead;
        }
    }
}
</code></pre>
<p>This step saves each lead as an Eloquent model, and returns a collection of the saved models, which are passed to the final step:</p>
<pre><code class="lang-php">&lt;?php

namespace App\Stages;

use App\Contracts\Services\MailingList;
use Illuminate\Support\Collection;

class AddDataToList
{
    protected $list;

    public function __construct(MailingList $list)
    {
        $this-&gt;list = $list;
    }

    public function __invoke(Collection $data)
    {
        return $data-&gt;each(function ($item) {
            $this-&gt;list-&gt;add([
                &#39;name&#39; =&gt; $item-&gt;name,
                &#39;email&#39; =&gt; $item-&gt;email
            ]);
        });
    }
}
</code></pre>
<p>This step uses a wrapper class for a mailing service, which is passed through as a dependency in the constructor. The <code>__invoke()</code> method then loops through each Eloquent model and uses it to fetch the data, which is then added to the list. With our stages complete, we can now put them together in our controller:</p>
<pre><code class="lang-php">&lt;?php

namespace App\Http\Controllers;

use Illuminate\Http\Request;
use App\Stages\FormatData;
use App\Stages\SaveData;
use App\Stages\AddDataToList;
use League\Pipeline\Pipeline;
use Illuminate\Support\Collection;

class WebhookController extends Controller
{
    public function store(Request $request, Pipeline $pipeline, FormatData $formatData, SaveData $savedata, AddDataToList $addData)
    {
        try {
            $data = Collection::make($request-&gt;get(&#39;data&#39;));
            $pipe = $pipeline-&gt;pipe($formatData)
                -&gt;pipe($saveData)
                -&gt;pipe($addData);
            $pipe-&gt;process($data);
        } catch (\Exception $e) {
            // Handle exception
        }
    }
}
</code></pre>
<p>As mentioned above, we extract the request data (assumed to be an array of data for a webhook), and convert it into a collection. Then, we put together our pipeline. Note that we use dependency injection to fetch the steps - feel free to use method or constructor injection as appropriate. We instantiate our pipeline, and call the <code>pipe()</code> method multiple times to add new stages.</p>
<p>Finally we pass the data through to our pipe for processing by calling the <code>process()</code> method, passing in the initial data. Note that we can wrap the whole thing in a <code>try...catch</code> statement to handle exceptions, so if something happens that would mean we would want to cease processing at that point, we can throw an exception in the stage and handle it outside the pipeline.</p>
<p>This means that our controller is kept very simple. It just gets the data as a collection, then puts the pipeline together and passes the data through. If we subsequently had to write an Artisan task to do something similar from the command line, we could fetch the data via a CSV reader class, and then pass it to the same pipeline. If we needed to change the format of the initial data, we could replace the <code>FormatData</code> class with a single separate class with very little trouble.</p>
<p>Another thing you can do with the League pipeline package, but I haven’t yet had the occasion to try, is use <code>League\Pipeline\PipelineBuilder</code> to build pipelines in a more dynamic fashion. You can make steps conditional, as in this example:</p>
<pre><code class="lang-php">&lt;?php

use League\Pipeline\PipelineBuilder;

$builder = (new PipelineBuilder)
    -&gt;add(new FormatData);
if ($data[&#39;type&#39;] = &#39;foo&#39;) {
    $builder-&gt;add(new HandleFooType);
}
$builder-&gt;add(new SaveData);
$pipeline = $builder-&gt;build();
$pipeline-&gt;process($data);
</code></pre>
<p>The pipeline pattern isn’t appropriate for every situation, but for anything that involves a set of operations on the same data, it makes a lot of sense, and can make it easy to break larger operations into smaller steps that are easier to understand, test, and re-use.</p>
]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Replacing switch statements with polymorphism in PHP]]></title>
        <id>https://matthewdaly.co.uk/blog/2018/10/03/replacing-switch-statements-with-polymorphism-in-php/</id>
        <link href="https://matthewdaly.co.uk/blog/2018/10/03/replacing-switch-statements-with-polymorphism-in-php/">
        </link>
        <updated>2018-10-03T22:07:33Z</updated>
        <summary type="html"><![CDATA[<p>For the last few months, I’ve been making a point of picking up on certain antipatterns, and ways to avoid or remove them. One I’ve seen a lot recently is unnecessary large switch-case or if-else statements. For instance, here is a simplified example of one of these, which renders links to different objects:</p>
<pre><code class="lang-php">&lt;?php

switch ($item-&gt;getType()) {
    case &#39;audio&#39;:
        $media = new stdClass;
        $media-&gt;type = &#39;audio&#39;;
        $media-&gt;duration = $item-&gt;getLength();
        $media-&gt;name = $item-&gt;getName();
        $media-&gt;url = $item-&gt;getUrl();
    case &#39;video&#39;:
        $media = new stdClass;
        $media-&gt;type = &#39;video&#39;;
        $media-&gt;duration = $item-&gt;getVideoLength();
        $media-&gt;name = $item-&gt;getTitle();
        $media-&gt;url = $item-&gt;getUrl();
}
return &#39;&lt;a href=&quot;&#39;.$media-&gt;url.&#39;&quot; class=&quot;&#39;.$media-&gt;type.&#39;&quot; data-duration=&quot;&#39;.$media-&gt;duration.&#39;&quot;&gt;&#39;.$media-&gt;name.&#39;&lt;/a&gt;&#39;;
</code></pre>
<p>There are a number of problems with this, most notably the fact that it’s doing a lot of work to try and create a new set of objects that behave consistently. Instead, your objects should be polymorphic - in other words, you should be able to treat the original objects the same.</p>
<p>While strictly speaking you don’t need one, it’s a good idea to create an interface that defines the required methods. That way, you can have those objects implement that interface, and be certain that they have all the required methods:</p>
<pre><code class="lang-php">&lt;?php

namespace App\Contracts;

interface MediaItem
{
    public function getLength(): int;

    public function getName(): string;

    public function getType(): string;

    public function getUrl(): string;
}
</code></pre>
<p>Then, you need to implement that interface in your objects. It doesn’t matter if the implementations are different, as long as the methods exist. That way, objects can define how they return a particular value, which is simpler and more logical than defining it in a large switch-case statement elsewhere. It also helps to prevent duplication. Here’s what the audio object might look like:</p>
<pre><code class="lang-php">&lt;?php

namespace App\Models;

use App\Contracts\MediaItem;

class Audio implements MediaItem
{
    public function getLength(): int
    {
        return $this-&gt;length;
    }

    public function getName(): string
    {
        return $this-&gt;name;
    }

    public function getType(): string
    {
        return $this-&gt;type;
    }

    public function getUrl(): string
    {
        return $this-&gt;url;
    }
}
</code></pre>
<p>And here’s a similar example of the video object:</p>
<pre><code class="lang-php">&lt;?php

namespace App\Models;

use App\Contracts\MediaItem;

class Video implements MediaItem
{
    public function getLength(): int
    {
        return $this-&gt;getVideoLength();
    }

    public function getName(): string
    {
        return $this-&gt;getTitle();
    }

    public function getType(): string
    {
        return $this-&gt;type;
    }

    public function getUrl(): string
    {
        return $this-&gt;url;
    }
}
</code></pre>
<p>With that done, the code to render the links can be greatly simplified:</p>
<pre><code class="lang-php">&lt;?php
return &#39;&lt;a href=&quot;&#39;.$item-&gt;getUrl().&#39;&quot; class=&quot;&#39;.$item-&gt;getType().&#39;&quot; data-duration=&quot;&#39;.$item-&gt;getLength().&#39;&quot;&gt;&#39;.$media-&gt;getName().&#39;&lt;/a&gt;&#39;;
</code></pre>
<p>Because we can use the exact same methods and get consistent responses, yet also allow for the different implementations within the objects, this approach allows for much more elegant and readable code. Different objects can be treated in the same way without the need for writing extensive if or switch statements.</p>
<p>I haven’t had the occasion to do so, but in theory this approach is applicable in other languages, such as Javascript or Python (although these languages don’t have the concept of interfaces). Since discovering the swtch statement antipattern and how to replace it with polymorphism, I’ve been able to remove a lot of overly complex code.</p>
]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Career direction after seven years]]></title>
        <id>https://matthewdaly.co.uk/blog/2018/09/25/career-direction-after-seven-years/</id>
        <link href="https://matthewdaly.co.uk/blog/2018/09/25/career-direction-after-seven-years/">
        </link>
        <updated>2018-09-25T21:03:29Z</updated>
        <summary type="html"><![CDATA[<p>Earlier this month, I passed the seven year anniversary of starting my first web dev job. That job never really worked out, for various reasons, but since then I’ve had an interesting time of it. I’ve diversified into app development via Phonegap, and I’ve worked with frameworks that didn’t exist when I first started. So it seems a good opportunity to take stock and think about where I want to head next.</p>
<p>Sometimes these posts are where someone announces they’re leaving their current role, but that’s not the case here - I’m pretty happy where I am right now. I am maintaining a legacy project, but I do feel like I’m making a difference and it’s slowly becoming more pleasant to work with, and I’m learning a lot about applying design patterns, so I think where I am right now is a good place for me. However, it’s a useful exercise to think about what I want to do, where I want to concentrate my efforts, and what I want to learn about.</p>
<p>So, here are my thoughts about where I want to go in future:</p>
<ul>
<li>I really enjoy working with React, and I want to do so much more than I have in the past, possibly including React Native. Ditto with Redux.</li>
<li>Much as I love Django, it’s unlikely I’ll be using it again in the future, as it’s simply not in much demand where I live. In 2015, I was working at a small agency with a dev team of three, including me, and it became apparent that we needed to standardise on a single framework. I’d been using CodeIgniter on and off for several years, but it was tired and dated, yet I couldn’t justify using Django because no-one else was familiar with Python, so we settled on Laravel. Ever since, Laravel has been my go-to framework - Django does some things better (Django REST Framework remains the best way I’ve ever found to create a REST API), but Laravel does enough stuff well enough that I can use it for most things I need, so it’s a good default option.</li>
<li>I <em>really</em> don’t want to work with Wordpress often, and if I do, I’d feel a lot better about it if I used Bedrock. Just churning out boilerplate sites is anathema to me - I’d much rather do something more interesting, even if it were paid worse.</li>
<li>PHP is actually pretty nice these days (as long as you’re not dealing with a legacy application), and I generally don’t mind working with it, as long as it’s fairly modern.</li>
<li>I enjoy mentoring and coaching others, and I’d like to do that a lot more often than I have been doing. Mentoring and coaching is a big part of being a senior developer, since a good mentor can quickly bring inexperienced developers up to a much higher standard, and hugely reduces the amount of horrible legacy code that needs to be maintained. I was without an experienced mentor for much of my career, and in retrospect it held me back - having someone around to teach me about TDD and design patterns earlier would have helped no end. Also, I find it the single most rewarding part of my job.</li>
<li>I have absolutely no desire whatsoever to go into management, or leave coding behind in any way, shape or form. I’ve heard it said before that Microsoft have two separate career tracks for developers, one through people management, the other into a software architect role, and were I there, I would definitely opt for the latter.</li>
<li>I’m now less interested in learning new frameworks or languages than I am in picking up and applying new design patterns, and avoiding antipatterns - they’re the best way to improve your code quality. I’ve learned the hard way that the hallmark of a skilled developer’s code is not the complexity, but the simplicity - I can now recognise the convoluted code I wrote earlier in my career as painful to maintain, and can identify it in legacy projects.</li>
<li>I’ve always used linters and other code quality tools, and I’m eager to evangelise their usage.</li>
<li>I’ve been a proponent of TDD for several years now, and that’s going to continue - I’ve not only seen how many things it catches when you have tests, but also how painful it is when you have a large legacy project with no tests at all, and I’m absolutely staggered that anyone ever continues to write non-trivial production code without any sort of tests.</li>
<li>I want to understand the frameworks I use at a deeper level - it’s all too easy to just treat them as magic, when there are huge benefits to understanding how your framework works under the bonnet, and how to swap out the framework’s functionality for alternative implementations.</li>
<li>I’d like to get involved in more IoT-related projects - guess the 3 Raspberry Pi’s and the Arduino I have gathering dust at home need to get some more use…</li>
<li>Chat interfaces are interesting - I built an Alexa skill recently, which was fun and useful, and I’d like to do stuff like that more often.</li>
</ul>
<p>So, after seven years, that’s where I see myself going in future. I think I’m in a good place to do that right now, and I’ll probably stay where I am for a good long while yet. The first seven years of my web dev career have been interesting, and I’m eager to see what the next seven bring.</p>
]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[How I'm refactoring a Zend 1 legacy project]]></title>
        <id>https://matthewdaly.co.uk/blog/2018/09/24/how-i&apos;m-refactoring-a-zend-1-legacy-project/</id>
        <link href="https://matthewdaly.co.uk/blog/2018/09/24/how-i&apos;m-refactoring-a-zend-1-legacy-project/">
        </link>
        <updated>2018-09-24T21:30:46Z</updated>
        <summary type="html"><![CDATA[<p>In my current job I’ve been maintaining and developing a Zend 1 legacy project for the best part of a year. It has to be said, it’s the worst code base I have ever seen, with textbook examples of many antipatterns, spaghetti jQuery, copy-pasted code and overly complex methods. It’s a fairly typical example of a project built on an older MVC framework by inexperienced developers (I’ve been responsible for building similar things in my CodeIgniter days).</p>
<p>In this article I’ll go through some of the steps I’ve taken to help bring this legacy project under control. Not all of them are complete as at time of writing, but they’ve all helped to make this decidedly crappy project somewhat better. In working with this legacy project, I’ve found Paul Jones’ book <em>Modernizing Legacy Applications in PHP</em> to be very useful, and if you’re working on a similar legacy project, I highly recommend investing in a copy. I’ve also found <a href="https://sourcemaking.com/">Sourcemaking</a> to be a useful resource in identifying antipatterns in use, refactoring strategies, and applicable design patterns.</p>
<h1 id="moving-to-git">Moving to Git</h1>
<p>When I first started working on the project, the repository was in Subversion, and was absolutely colossal - checking it out took two hours! Needless to say, my first action was to migrate it to Git. I used <a href="https://john.albin.net/git/convert-subversion-to-git">this post</a> as a guide, and it was pretty straightforward, but took all of my first day.</p>
<h1 id="adding-migrations">Adding migrations</h1>
<p>The next job involved making some changes to the database. Unfortunately, Zend 1 doesn’t include migrations, and no-one had added a third party solution. I therefore did some research and wound up stumbling across <a href="https://phinx.org/">Phinx</a>, which is a standalone migration package with a command-line runner. Using that, it was straightforward to start adding migrations to make any necessary changes to the database structure and fixtures.</p>
<h1 id="moving-dependencies-to-composer">Moving dependencies to Composer</h1>
<p>The project was using Composer, but only to a limited degree - the framework itself was in the <code>library/</code> folder, and several other dependencies were also stored here. The <code>vendor/</code> directory was also checked into version control. I therefore took the vendor folder out of Git, and added <code>zendframework/zendframework1</code> as a dependency. This drastically reduced the size of the repository.</p>
<h1 id="cleaning-up-commented-code">Cleaning up commented code</h1>
<p>There was an awful lot of commented code. Some of it was even commented out incorrectly (PHP code commented out with HTML comments). I’m of the school of thought that commented code is best deleted without a second thought, since it can be retrieved from version control, and it can be confusing, so I’ve been removing any commented code I come across.</p>
<h1 id="refactoring-duplicate-code">Refactoring duplicate code</h1>
<p>One of the biggest problems with the code base was the high level of duplication - a lot of code, particularly in the view layer, had been copied and pasted around. Running PHPCPD on the repository showed that, not including the views, around 12% of the code base was copied-and-pasted, which is a horrific amount. I therefore started aggressively refactoring duplicate code out into helpers and traits. As at today, the amount of duplication excluding the views is around 2.6%, which is obviously a big improvement.</p>
<h1 id="refactoring-object-creation-code-into-persisters">Refactoring object creation code into persisters</h1>
<p>There was some extremely complex code for creating and updating various objects that was jammed into the controllers, and involved a lot of duplicate code. I’ve used dedicated persister classes in the past with great effect, so I pulled that code out into persisters to centralise the logic about the creation of different objects. It’s still a lot more convoluted than I’d like, but at least now it’s out of the controllers and can be tested to some extent.</p>
<h1 id="creating-repositories">Creating repositories</h1>
<p>One of the most problematic parts of the code base is the models. Whoever was responsible for them couldn’t seem to decide whether they represented a single domain object, or a container for methods for getting those objects, so both responsibilities were mixed up in the same class. This means you had to instantiate an object, then use it to call one of the methods to get another instance of that object, as in this example:</p>
<pre><code class="lang-php">$media = new Application_Model_Media;
$media = $media-&gt;find(1);
</code></pre>
<p>I’ve therefore resolved to pull those methods out into separate repository classes, leaving the models as pure domain objects. Unfortunately, the lack of dependency injection makes it problematic to instantiate the repositories. For that reason, right now the repositories only implement static methods - it’s not ideal, but it’s better than what we have now.</p>
<p>I started out by creating interfaces for the methods I wanted to migrate, and had the models implement them. Then, I moved those methods from the model to the repository classes and amended all references to them, before removing the interfaces from the models. Now, a typical find request looks like this:</p>
<pre><code class="lang-php">$media = App\Repository\Media::find(1);
</code></pre>
<p>It’s not done yet, but over half of them have been migrated.</p>
<p>Once that’s done, I’ll then be in a position to look at refactoring the logic in the models to make them easier to work with - right now each model has dedicated setters and getters (as well as some horrific logic to populate them), and I’m considering amending them to allow access to the properties via the <code>__get()</code> and <code>__set()</code> magic methods. Another option is to consider migrating the database layer to Doctrine, since that way we can reuse the getters and setters, but I haven’t yet made a firm decision about that.</p>
<h1 id="adding-tests">Adding tests</h1>
<p>The poor design of this application makes it difficult to test, so right now the coverage is poor. I’ve been using Behat to produce a basic set of acceptance tests for some of the most fundamental functionality, but they’re brittle and can be broken by database changes. I’ve also added some (even more brittle) golden master tests using a technique I’ll mention in a later blog post. I have got unit tests for three of the persister classes and some utility classes I’ve added, but nowhere near the level I want.</p>
<h1 id="refactoring-code-out-of-the-fat-controllers">Refactoring code out of the fat controllers</h1>
<p>Fat controllers are an antipattern I’ve seen, and indeed been responsible for myself, in the past, and this project has them in spades - running PHP Mess Detector on them is pretty sobering. The overwhelming majority of the code base is concentrated in the controllers, and it’s going to take a long time to refactor it into other classes.</p>
<p>Zend 1 does have the concept of controller helpers, and that’s been useful for removing some duplicate code, while more shared code has been refactored out into traits. In addition, the utilities I’ve added include a Laravel-style collection class, and using that I’ve been able to refactor a lot of quite complex array handling into much simpler chained collection handling. However, this is still going to take a lot of effort.</p>
<h1 id="adding-events">Adding events</h1>
<p>The lack of a decent event system caused particular problems when I was asked to add tracking of when a user views certain resources, so I used the <a href="http://event.thephpleague.com/2.0/">PHP League’s Event package</a> for this. I’ve started moving some other functionality to event listeners too, but this is another thing that will take a long time.</p>
<h1 id="refactoring-the-front-end">Refactoring the front end</h1>
<p>Like many legacy projects, the front end is a horrible mess of jQuery spaghetti code, with some Handlebars templates thrown in here and there for good measure. It’s easily complex enough that it would benefit from a proper front-end framework, but a full rewrite is out of the question.</p>
<p>I was recently asked to add two new modals in the admin interface, and decided that it was worth taking a new approach rather than adding yet more jQuery spaghetti. Angular 1 is on its way out, so that wasn’t an option, and Angular 2+ would necessitate using Typescript, which would likely be problematic in the context of a legacy app, as well as the complexity being an issue. Vue was a possibility, but I always feel like Vue tries to do too much. Instead, I decided to go for React, because:</p>
<ul>
<li>I’ve always enjoyed working with React, even though I haven’t had much chance to do so in the past.</li>
<li>We’re using Laravel Mix for processing the CSS and JS files (it can be used on non-Laravel projects), and it has a preset for React</li>
<li>React is well-suited to being added incrementally to existing projects without the need for a full rewrite (after all, it works for Facebook…), so it was straightforward to do a single modal with it</li>
<li>It’s easy to test - you can use snapshot tests to check it remains consistent, and using Enzyme it’s straightforward to navigate the rendered component for other tests</li>
</ul>
<p>Both modals turned out very well, and went live recently. The first one took a fair while to write, and then when I wrote the second one, I had to spend some time making the sub-components more generic and pulling some functionality out into a higher order component, but now that that’s done it should be straightforward to write more.</p>
<p>In the longer term I plan to migrate more and more of the admin to React over time. The front end also has a new home page on the cards, and the plan is to use React for that too. Once the whole UI is using React, that will have eliminated most, if not all, of the problems with duplicate code in the view layer, as well as allowing for eventually turning the application into a single-page web app.</p>
<h1 id="upgrading-the-php-version-and-migrating-to-a-new-server">Upgrading the PHP version and migrating to a new server</h1>
<p>When I started work on the project, it was running on an old server running PHP 5.4, but there were plans to migrate to a new server running PHP 5.6. The lack of tests made it difficult to verify it wouldn’t break in 5.6, but using PHP Compatibility and CodeSniffer I was able to find most of the problems. I ran it on PHP 5.6 locally during development so that any new development would be done on a more modern version. In the end, the migration to the new server was fairly seamless.</p>
<p>We will have to consider migrating to a newer PHP version again, since 5.6 is no longer supported as at the end of this year, but it may be too risky for now.</p>
<h1 id="namespacing-the-code">Namespacing the code</h1>
<p>As Zend 1 predates PHP namespaces, the code wasn’t namespaced. This is something I do plan to remedy - the form and model classes should be straightforward to namespace, but the controllers are a bit more problematic. I’m waiting on completing the repositories before I look at this.</p>
<h1 id="adding-psr-3-logging">Adding PSR-3 logging</h1>
<p>The existing logging solution was not all that great. It had drivers for several different logging solutions, but nothing terribly modern - one was for the now-discontinued Firebug extension for Firefox. However, it was fairly similar to PSR-3, so it wasn’t too much work to replace it. I installed Monolog, and amended the bootstrap file to store that as the logger in the Zend registry - that way, we could set up many different handlers. I now have it logging to a dedicated Slack channel when an error occurs in staging or production, which makes it much easier to detect problems. This would also make it easy to set up many other logging handlers, such as the ELK stack.</p>
<h1 id="debugging">Debugging</h1>
<p><a href="https://underground.works/clockwork/">Clockwork</a> is my usual PHP debugging solution, and the absence of support for it in Zend 1 made it difficult to work with. Fortunately, it’s quite straightforward to implement your own <a href="https://underground.works/clockwork/extending-data-sources?#content">data sources</a> for Clockwork. I set it up to use the aforementioned logger as a data source, as well as the <a href="https://framework.zend.com/manual/1.12/en/zend.db.profiler.html">Zend 1 profiler</a>. I also added a data source for the events implementation, and added a global <code>clock()</code> helper function, as well as one for the Symfony VarDumper component. Together these give me a reasonably good debugging experience.</p>
<h1 id="adding-console-commands">Adding console commands</h1>
<p>I’ve mentioned before that I’ve been using Symfony’s console component a lot lately, and this project is why. Zend 1 does not come with any sort of console task runner, and we needed an easy way to carry out certain tasks, such as:</p>
<ul>
<li>Setting up a stored procedure</li>
<li>Anonymizing user data with Faker</li>
<li>Regenerating durations for audio and video files</li>
</ul>
<p>In addition, I wanted a Laravel Tinker-style interactive shell. I was able to accomplish this with PsySh and the console components. For legacy projects that lack a console task runner, it’s worth considering adding one.</p>
<h1 id="configuration">Configuration</h1>
<p>The configuration system in Zend 1 is downright painful - it requires that you define multiple environments in there. I have integrated DotEnv, but only part of the configuration has been migrated over, so there’s still plenty of work there.</p>
<h1 id="what-s-left-to-do">What’s left to do</h1>
<p>The code base is in a much better state than it was, but there’s still an awful lot to do. Zend 1 does apparently still work with PHP 7.1, but not with 7.2, so at some point we’ll likely need to leave Zend 1 behind entirely. This process has already started with us ditching Zend_Log for Monolog, and over time I plan to replace the various components of Zend 1 with other packages, either ones from newer versions of Zend Framework, or elsewhere. While there are many articles about migrating Zend 1 to later versions, very few of them actually seem to go into much detail - certainly nothing as useful as a step-by-step guide.</p>
<p>The database layer is particularly bad, and refactoring some of the methods into repository classes is only the first step in bringing that under control. Once that’s finished, I’m going to start going through the models and seeing if any more methods would make more sense as static methods on the repository, and possibly rename some of them. Then, we can think about the possibility of either incrementally migrating to another database interface (either a newer version of Zend DB, or Doctrine), or refactoring the existing models to have less boilerplate by using magic methods instead of getters and setters.</p>
<p>Dependency injection is a must at some point, but isn’t practical right now - Zend 1 controllers implement an interface that defines the constructor arguments, so you can’t pass in any additional parameters, so that will need to wait until the controllers no longer use Zend 1. I have been using the Zend Registry as a poor man’s DI container, since it allows sharing of a single object throughout the application, but it’s not a good solution in the long term.</p>
<p>The routing is also painful - Zend 1’s routes are all stored in the bootstrap file. I’d prefer to use something like <code>league/route</code>, which would allow for handling different HTTP methods to the same route using different controller methods, making it easier to separate out handling of GET and POST requests.</p>
<p>I also want at some point to set up a queue system for processing video and audio content - at present it’s handled by running a shell command from PHP, which means you can’t easily get feedback if something goes wrong. Migrating that to a queue system, backed with something like Redis, would help a great deal.</p>
<h1 id="share-your-stories">Share your stories</h1>
<p>I’d love to hear any similar stories about refactoring legacy applications - how you’ve solved various problems with those legacy apps (or how you’d solve the ones I’ve had), tools you’ve used, and so on. Feel free to provide details in the comments.</p>
<p>A legacy project like this can be very frustrating to work with, but it can also feel quite rewarding to bring it under control over a period of time. My experience has been that you get the best results by working in small, regular steps, and over time your experience working with the code base will improve.</p>
]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mutation testing with Infection]]></title>
        <id>https://matthewdaly.co.uk/blog/2018/09/13/mutation-testing-with-infection/</id>
        <link href="https://matthewdaly.co.uk/blog/2018/09/13/mutation-testing-with-infection/">
        </link>
        <updated>2018-09-13T19:10:09Z</updated>
        <summary type="html"><![CDATA[<p>Writing automated tests is an excellent way of catching bugs during development and maintenance of your application, not to mention the other benefits. However, it’s hard to gauge the quality of your tests, particularly when you first start out. Coverage will give you a good idea of what code was actually run during the test, but it won’t tell you if the test itself actually tests anything worthwhile.</p>
<p><a href="https://infection.github.io/">Infection</a> is a mutation testing framework. The documentation defines mutation testing as follows:</p>
<blockquote>
<p>Mutation testing involves modifying a program in small ways. Each mutated version is called a Mutant. To assess the quality of a given test set, these mutants are executed against the input test set to see if the seeded faults can be detected. If mutated program produces failing tests, this is called a killed mutant. If tests are green with mutated code, then we have an escaped mutant.</p>
</blockquote>
<p>Infection works by running the test suite, carrying out a series of mutations on the source code in order to try to break the tests, and then collecting the results. The actual mutations carried out are not random - there is a set of mutations that get carried out every time, so results should be consistent. Ideally, all mutants should be killed by your tests - escaped mutants can indicate that either the line of mutated code is not tested, or the tests for that line are not very useful.</p>
<p>I decided to add mutation testing to my <a href="https://github.com/matthewbdaly/laravel-cart">Laravel shopping cart package</a>. In order to use Infection, you need to be able to generate code coverage, which means having either XDebug or phpdbg installed. Once Infection is installed (refer to the documentation for this), you can run this command in the project directory to configure it:</p>
<pre><code class="lang-bash">$ infection
</code></pre>
<p>Infection defaults to using PHPUnit for the tests, but it also supports PHPSpec. If you’re using PHPSpec, you will need to specify the testing framework like this:</p>
<pre><code class="lang-bash">$ infection --test-framework=phpspec
</code></pre>
<p>Since PHPSpec doesn’t support code coverage out of the box, you’ll need to install a package for that - I used <code>leanphp/phpspec-code-coverage</code>.</p>
<p>On first run, you’ll be prompted to create a configuration file. Your source directory should be straightforward to set up, but at the next step, if your project uses interfaces in the source directory, you should exclude them. The rest of the defaults should be fine.</p>
<p>I found that the first run gave a large number of uncovered results, but the second and later ones were more consistent - not sure if it’s an issue with my setup or not. Running it gave me this:</p>
<pre><code class="lang-bash">$ infection
You are running Infection with xdebug enabled.
    ____      ____          __  _
   /  _/___  / __/__  _____/ /_(_)___  ____ 
   / // __ \/ /_/ _ \/ ___/ __/ / __ \/ __ \
 _/ // / / / __/  __/ /__/ /_/ / /_/ / / / /
/___/_/ /_/_/  \___/\___/\__/_/\____/_/ /_/

    0 [&gt;---------------------------] &lt; 1 secRunning initial test suite...

PHPUnit version: 6.5.13

   27 [============================] 3 secs

Generate mutants...

Processing source code files: 5/5
Creating mutated files and processes: 43/43
.: killed, M: escaped, S: uncovered, E: fatal error, T: timed out

...................MMM...M.......M.........          (43 / 43)

43 mutations were generated:
      38 mutants were killed
       0 mutants were not covered by tests
       5 covered mutants were not detected
       0 errors were encountered
       0 time outs were encountered

Metrics:
         Mutation Score Indicator (MSI): 88%
         Mutation Code Coverage: 100%
         Covered Code MSI: 88%

Please note that some mutants will inevitably be harmless (i.e. false positives).

Time: 21s. Memory: 12.00MB
</code></pre>
<p>Our test run shows 5 escaped mutants, and the remaining 38 were killed. We can view the results by looking at the generated <code>infection-log.txt</code>:</p>
<pre><code class="lang-txt">Escaped mutants:
================


1) /home/matthew/Projects/laravel-cart/src/Services/Cart.php:132    [M] DecrementInteger

--- Original
+++ New
@@ @@
     {
         $content = Collection::make($this-&gt;all())-&gt;map(function ($item) use($rowId) {
             if ($item[&#39;row_id&#39;] == $rowId) {
-                if ($item[&#39;qty&#39;] &gt; 0) {
+                if ($item[&#39;qty&#39;] &gt; -1) {
                     $item[&#39;qty&#39;] -= 1;
                 }
             }


2) /home/matthew/Projects/laravel-cart/src/Services/Cart.php:132    [M] OneZeroInteger

--- Original
+++ New
@@ @@
     {
         $content = Collection::make($this-&gt;all())-&gt;map(function ($item) use($rowId) {
             if ($item[&#39;row_id&#39;] == $rowId) {
-                if ($item[&#39;qty&#39;] &gt; 0) {
+                if ($item[&#39;qty&#39;] &gt; 1) {
                     $item[&#39;qty&#39;] -= 1;
                 }
             }


3) /home/matthew/Projects/laravel-cart/src/Services/Cart.php:132    [M] GreaterThan

--- Original
+++ New
@@ @@
     {
         $content = Collection::make($this-&gt;all())-&gt;map(function ($item) use($rowId) {
             if ($item[&#39;row_id&#39;] == $rowId) {
-                if ($item[&#39;qty&#39;] &gt; 0) {
+                if ($item[&#39;qty&#39;] &gt;= 0) {
                     $item[&#39;qty&#39;] -= 1;
                 }
             }


4) /home/matthew/Projects/laravel-cart/src/Services/Cart.php:133    [M] Assignment

--- Original
+++ New
@@ @@
         $content = Collection::make($this-&gt;all())-&gt;map(function ($item) use($rowId) {
             if ($item[&#39;row_id&#39;] == $rowId) {
                 if ($item[&#39;qty&#39;] &gt; 0) {
-                    $item[&#39;qty&#39;] -= 1;
+                    $item[&#39;qty&#39;] = 1;
                 }
             }
             return $item;


5) /home/matthew/Projects/laravel-cart/src/Services/Cart.php:197    [M] OneZeroInteger

--- Original
+++ New
@@ @@
      */
     private function hasStringKeys(array $items)
     {
-        return count(array_filter(array_keys($items), &#39;is_string&#39;)) &gt; 0;
+        return count(array_filter(array_keys($items), &#39;is_string&#39;)) &gt; 1;
     }
     /**
      * Validate input

Timed Out mutants:
==================

Not Covered mutants:
====================
</code></pre>
<p>This displays the mutants that escaped, and include a diff of the changed code, so we can see that all of these involve changing the comparison operators.</p>
<p>The last one can be resolved easily because the comparison is superfluous - the result of <code>count()</code> can be evaluated as true or false by itself, so removing the <code>&gt; 0</code> at the end in the test solves the problem quite neatly.</p>
<p>The other four mutations are somewhat harder. They all amend the <code>decrement</code> method’s conditions, showing that a single assertion doesn’t really fully check the behaviour. Here’s the current test for that method:</p>
<pre><code class="lang-php">&lt;?php

namespace Tests\Unit\Services;

use Tests\TestCase;
use Matthewbdaly\LaravelCart\Services\Cart;
use Mockery as m;

class CartTest extends TestCase
{
    /**
     * @dataProvider arrayProvider
     */
    public function testCanDecrementQuantity($data)
    {
        $data[0][&#39;row_id&#39;] = &#39;my_row_id_1&#39;;
        $data[1][&#39;row_id&#39;] = &#39;my_row_id_2&#39;;
        $newdata = $data;
        $newdata[1][&#39;qty&#39;] = 1;
        $session = m::mock(&#39;Illuminate\Contracts\Session\Session&#39;);
        $session-&gt;shouldReceive(&#39;get&#39;)-&gt;with(&#39;Matthewbdaly\LaravelCart\Services\Cart&#39;)-&gt;once()-&gt;andReturn($data);
        $session-&gt;shouldReceive(&#39;put&#39;)-&gt;with(&#39;Matthewbdaly\LaravelCart\Services\Cart&#39;, $newdata)-&gt;once();
        $uniqid = m::mock(&#39;Matthewbdaly\LaravelCart\Contracts\Services\UniqueId&#39;);
        $cart = new Cart($session, $uniqid);
        $this-&gt;assertEquals(null, $cart-&gt;decrement(&#39;my_row_id_2&#39;));
    }
}
</code></pre>
<p>It should be possible to decrement it if the quantity is more than zero, but not to go any lower. However, our current test does not catch anything but decrementing it from 2 to 1, which doesn’t fully demonstrate this. We therefore need to add a few more assertions to cover taking it down to zero, and then trying to decrement it again. Here’s how we might do that.</p>
<pre><code class="lang-php">&lt;?php

namespace Tests\Unit\Services;

use Tests\TestCase;
use Matthewbdaly\LaravelCart\Services\Cart;
use Mockery as m;

class CartTest extends TestCase
{
    /**
     * @dataProvider arrayProvider
     */
    public function testCanDecrementQuantity($data)
    {
        $data[0][&#39;row_id&#39;] = &#39;my_row_id_1&#39;;
        $data[1][&#39;row_id&#39;] = &#39;my_row_id_2&#39;;
        $newdata = $data;
        $newdata[1][&#39;qty&#39;] = 1;
        $session = m::mock(&#39;Illuminate\Contracts\Session\Session&#39;);
        $session-&gt;shouldReceive(&#39;get&#39;)-&gt;with(&#39;Matthewbdaly\LaravelCart\Services\Cart&#39;)-&gt;once()-&gt;andReturn($data);
        $session-&gt;shouldReceive(&#39;put&#39;)-&gt;with(&#39;Matthewbdaly\LaravelCart\Services\Cart&#39;, $newdata)-&gt;once();
        $uniqid = m::mock(&#39;Matthewbdaly\LaravelCart\Contracts\Services\UniqueId&#39;);
        $cart = new Cart($session, $uniqid);
        $this-&gt;assertEquals(null, $cart-&gt;decrement(&#39;my_row_id_2&#39;));
        $newerdata = $newdata;
        $newerdata[1][&#39;qty&#39;] = 0;
        $session-&gt;shouldReceive(&#39;get&#39;)-&gt;with(&#39;Matthewbdaly\LaravelCart\Services\Cart&#39;)-&gt;once()-&gt;andReturn($newdata);
        $session-&gt;shouldReceive(&#39;put&#39;)-&gt;with(&#39;Matthewbdaly\LaravelCart\Services\Cart&#39;, $newerdata)-&gt;once();
        $this-&gt;assertEquals(null, $cart-&gt;decrement(&#39;my_row_id_2&#39;));
        $session-&gt;shouldReceive(&#39;get&#39;)-&gt;with(&#39;Matthewbdaly\LaravelCart\Services\Cart&#39;)-&gt;once()-&gt;andReturn($newerdata);
        $session-&gt;shouldReceive(&#39;put&#39;)-&gt;with(&#39;Matthewbdaly\LaravelCart\Services\Cart&#39;, $newerdata)-&gt;once();
        $this-&gt;assertEquals(null, $cart-&gt;decrement(&#39;my_row_id_2&#39;));
    }
}
</code></pre>
<p>If we re-run Infection, we now get a much better result:</p>
<pre><code class="lang-bash">$ infection
You are running Infection with xdebug enabled.
    ____      ____          __  _
   /  _/___  / __/__  _____/ /_(_)___  ____ 
   / // __ \/ /_/ _ \/ ___/ __/ / __ \/ __ \
 _/ // / / / __/  __/ /__/ /_/ / /_/ / / / /
/___/_/ /_/_/  \___/\___/\__/_/\____/_/ /_/

Running initial test suite...

PHPUnit version: 6.5.13

   22 [============================] 3 secs

Generate mutants...

Processing source code files: 5/5
Creating mutated files and processes: 41/41
.: killed, M: escaped, S: uncovered, E: fatal error, T: timed out

.........................................            (41 / 41)

41 mutations were generated:
      41 mutants were killed
       0 mutants were not covered by tests
       0 covered mutants were not detected
       0 errors were encountered
       0 time outs were encountered

Metrics:
         Mutation Score Indicator (MSI): 100%
         Mutation Code Coverage: 100%
         Covered Code MSI: 100%

Please note that some mutants will inevitably be harmless (i.e. false positives).

Time: 19s. Memory: 12.00MB
</code></pre>
<p>Code coverage only tells you what lines of code are actually executed - it doesn’t tell you much about how effectively that line of code is tested. Infection gives you a different insight into the quality of your tests, helping to write better ones. I’ve so far found it very useful for getting feedback on the quality of my tests. It’s interesting that PHPSpec tests seem to have a consistently lower proportion of escaped mutants than PHPUnit ones - perhaps the more natural workflow when writing specs with PHPSpec makes it easier to write good tests.</p>
]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Switching from Vim to Neovim]]></title>
        <id>https://matthewdaly.co.uk/blog/2018/09/09/switching-from-vim-to-neovim/</id>
        <link href="https://matthewdaly.co.uk/blog/2018/09/09/switching-from-vim-to-neovim/">
        </link>
        <updated>2018-09-09T12:40:35Z</updated>
        <summary type="html"><![CDATA[<p>I honestly thought it would never happen. I’ve been using Vim since 2008, and every other editor I’ve tried (including VSCode, Emacs, Sublime Text and Atom) hasn’t come up to scratch. There were a few useful features in PHPStorm, to be fair, but nothing that justified the bother of moving. Also, I suffer from a degree of RSI from my prior career as an insurance clerk (years of using crap keyboards and mice on Windows XP took its toll…), and Vim has always been the most RSI-friendly editor I found.</p>
<p>Yet I have actually gone ahead and migrated away… to Neovim. Of course, the fact that the workflow is essentially identical helps in the migration process, as does the fact that it supports most of the same plugins.</p>
<p>My workflow has always been strongly CLI-based. I use GNU Screen and Byobu together to run multiple “tabs” in the terminal, so the lack of GUI support in Neovim doesn’t bother me in the slightest. The only change I really made was to my <code>.bash_aliases</code> so that the Vim command ran <code>screen -t Vim nvim</code>, so that it would open up Neovim rather than Vim in a new Screen tab.</p>
<p>Initially I switched straight over to using the same settings and plugins I had with Vim, and they worked seamlessly. However, after a while I decided to use the opportunity to completely overhaul the plugins and settings I used and largely start over - cull the ones I no longer needed, add some new ones, and comment it properly.</p>
<h2 id="loading-plugins">Loading plugins</h2>
<p>I used to use Pathogen to manage my Vim plugins, but it didn’t actually import the plugins itself, and just provided a structure for them. This meant that the only practical way I found to pull in third-party plugins was to set them up as Git submodules, meaning I had to store my configuration in version control and clone it recursively onto a new machine. It also made updating cumbersome.</p>
<p>Now I’ve switched to <a href="https://github.com/junegunn/vim-plug">vim-plug</a>, which makes things much easier. I can define my dependencies in my <code>.config/nvim/init.vim</code> and pull them in with <code>PlugInstall</code>. If I want to update them, I run <code>PlugUpdate</code>, or if I need to add something else, I merely add it in the file and run <code>PlugInstall</code> again. Nice and easy.</p>
<p>The first section of my configuration file loads the dependencies:</p>
<pre><code class="lang-vim">call plug#begin()

&quot; NERDTree
Plug &#39;scrooloose/nerdtree&#39;

&quot; Git integration
Plug &#39;tpope/vim-fugitive&#39;
Plug &#39;airblade/vim-gitgutter&#39;

&quot; Linting
Plug &#39;neomake/neomake&#39;
Plug &#39;w0rp/ale&#39;

&quot; PHP-specific integration
Plug &#39;phpactor/phpactor&#39; ,  {&#39;do&#39;: &#39;composer install&#39;, &#39;for&#39;: &#39;php&#39;}
Plug &#39;ncm2/ncm2&#39;
Plug &#39;roxma/nvim-yarp&#39;
Plug &#39;phpactor/ncm2-phpactor&#39;

&quot; Snippets
Plug &#39;SirVer/ultisnips&#39;
Plug &#39;honza/vim-snippets&#39;

&quot; Comments
Plug &#39;tpope/vim-commentary&#39;

&quot; Search
Plug &#39;ctrlpvim/ctrlp.vim&#39;

&quot; Syntax
Plug &#39;sheerun/vim-polyglot&#39;
Plug &#39;matthewbdaly/vim-filetype-settings&#39;

&quot; Themes
Plug &#39;nanotech/jellybeans.vim&#39; , {&#39;as&#39;: &#39;jellybeans&#39;}

call plug#end()
</code></pre>
<p>As always, it’s a good idea to comment your config and try to group things logically. Note that I have one plugin of my own listed here - this is just a collection of settings for different filetypes, such as making Javascript files use 2 spaces for indentation, and it’s easier to keep that in a repository and pull it in as a dependency.</p>
<h2 id="completion">Completion</h2>
<p>The next part of the config deals with configuration. Most of the time the default omnicompletion is pretty good, but in the process of building out this config, I discovered PHPActor, which has massively improved my development experience with PHP - it finally provides completion as good as most IDE’s, and also provides similar refactoring tools. My config for completion currently looks like this:</p>
<pre><code class="lang-vim">&quot;Completion
autocmd FileType * setlocal formatoptions-=c formatoptions-=r formatoptions-=o
set ofu=syntaxcomplete#Complete
autocmd FileType php setlocal omnifunc=phpactor#Complete
let g:phpactorOmniError = v:true
autocmd BufEnter * call ncm2#enable_for_buffer()
set completeopt=noinsert,menuone,noselect
</code></pre>
<h2 id="general-config">General config</h2>
<p>This is a set of standard settings for the general behaviour of the application, such as setting the colorscheme and default indentation levels. I also routinely disable the mouse because it bugs me.</p>
<pre><code class="lang-vim">&quot;General
syntax on
colorscheme jellybeans
set nu
filetype plugin indent on
set nocp
set ruler
set wildmenu
set mouse-=a
set t_Co=256

&quot;Code folding
set foldmethod=manual

&quot;Tabs and spacing
set autoindent
set cindent
set tabstop=4
set expandtab
set shiftwidth=4
set smarttab

&quot;Search
set hlsearch
set incsearch
set ignorecase
set smartcase
set diffopt +=iwhite
</code></pre>
<h2 id="markdown-configuration">Markdown configuration</h2>
<p>This section sets the file type for Markdown. It disables the Markdown plugin included in <code>vim-polyglot</code> as I had problems with it, and sets the languages that will be highlighted in fenced code blocks. I may at some point migrate this to the filetype repository.</p>
<pre><code class="lang-vim">&quot;Syntax highlighting in Markdown
au BufNewFile,BufReadPost *.md set filetype=markdown
let g:polyglot_disabled = [&#39;markdown&#39;]
let g:markdown_fenced_languages = [&#39;bash=sh&#39;, &#39;css&#39;, &#39;django&#39;, &#39;javascript&#39;, &#39;js=javascript&#39;, &#39;json=javascript&#39;, &#39;perl&#39;, &#39;php&#39;, &#39;python&#39;, &#39;ruby&#39;, &#39;sass&#39;, &#39;xml&#39;, &#39;html&#39;, &#39;vim&#39;]
</code></pre>
<h2 id="neomake">Neomake</h2>
<p>I used to use Syntastic for checking my code for errors, but I’ve always found it problematic - it was slow and would often block the editor for some time. Neovim does have support for asynchronous jobs (as does Vim 8), but Syntastic doesn’t use it, so I decided to look elsewhere.</p>
<p>Neomake seemed a lot better, so I migrated over to it. It doesn’t require much configuration, and it’s really fast - unlike Syntastic, it supports asynchronous jobs. This part of the config sets it up to run on changes with no delay in writing, so I get near-instant feedback if a syntax error creeps in, and it doesn’t block the editor the way Syntastic used to.</p>
<pre><code class="lang-vim">&quot; Neomake config
&quot; Full config: when writing or reading a buffer, and on changes in insert and
&quot; normal mode (after 1s; no delay when writing).
call neomake#configure#automake(&#39;nrwi&#39;, 500)
</code></pre>
<h2 id="phpactor">PHPActor</h2>
<p>As mentioned above, PHPActor has dramatically improved my experience when coding in PHP by providing access to features normally found only in full IDE’s. Here’s the fairly standard config I use for the refactoring functionality:</p>
<pre><code class="lang-vim">&quot; PHPActor config
&quot; Include use statement
nmap &lt;Leader&gt;u :call phpactor#UseAdd()&lt;CR&gt;

&quot; Invoke the context menu
nmap &lt;Leader&gt;mm :call phpactor#ContextMenu()&lt;CR&gt;

&quot; Invoke the navigation menu
nmap &lt;Leader&gt;nn :call phpactor#Navigate()&lt;CR&gt;

&quot; Goto definition of class or class member under the cursor
nmap &lt;Leader&gt;o :call phpactor#GotoDefinition()&lt;CR&gt;

&quot; Transform the classes in the current file
nmap &lt;Leader&gt;tt :call phpactor#Transform()&lt;CR&gt;

&quot; Generate a new class (replacing the current file)
nmap &lt;Leader&gt;cc :call phpactor#ClassNew()&lt;CR&gt;

&quot; Extract expression (normal mode)
nmap &lt;silent&gt;&lt;Leader&gt;ee :call phpactor#ExtractExpression(v:false)&lt;CR&gt;

&quot; Extract expression from selection
vmap &lt;silent&gt;&lt;Leader&gt;ee :&lt;C-U&gt;call phpactor#ExtractExpression(v:true)&lt;CR&gt;

&quot; Extract method from selection
vmap &lt;silent&gt;&lt;Leader&gt;em :&lt;C-U&gt;call phpactor#ExtractMethod()&lt;CR&gt;
</code></pre>
<h2 id="summary">Summary</h2>
<p>Vim or Neovim configuration files are never static. Your needs are always changing, and you’re constantly discovering new plugins and new settings to try out, and keeping ones that prove useful. It’s been helpful to start over and ditch some plugins I no longer needed, pull in some new ones, and organise my configuration a bit better.</p>
<p>Now that I can set the dependencies in a text file rather than pulling them in as Git submodules, it makes more sense to keep my config in a <a href="https://gist.github.com/matthewbdaly/80b777ad3db885ebeecd27687fb121cd">Github Gist</a> rather than a Git repository, and that’s where I plan to retain it for now. Feel free to fork or cannibalize it for your own purposes if you wish.</p>
]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Better strings in PHP]]></title>
        <id>https://matthewdaly.co.uk/blog/2018/07/25/better-strings-in-php/</id>
        <link href="https://matthewdaly.co.uk/blog/2018/07/25/better-strings-in-php/">
        </link>
        <updated>2018-07-25T21:25:17Z</updated>
        <summary type="html"><![CDATA[<p>One of the weaknesses of PHP as a programming language is the limitations of some of the fundamental types. For instance, a string in PHP is a simple value, rather than an object, and doesn’t have any methods associated with it. Instead, to manipulate a string, you have to call all manner of functions. By comparison, in Python, not only can you call methods on a string, and receive a new string as the response, making them easily chainable, but you can also iterate through a string, as in this example:</p>
<pre><code class="lang-python">&gt;&gt;&gt; a = &#39;foo&#39;
&gt;&gt;&gt; a.upper()
&#39;FOO&#39;
&gt;&gt;&gt; a.lower()
&#39;foo&#39;
&gt;&gt;&gt; for letter in a:
...   print(letter)
... 
f
o
o
</code></pre>
<p>A little while back, I read Adam Wathan’s excellent book <em>Refactoring to Collections</em>, which describes how you can use a collection implementation (such as the one included with Laravel) to replace convoluted array manipulation with simpler, chainable calls to a collection object. Using this approach, you can turn something like this:</p>
<pre><code class="lang-php">$result = array_filter(
    array_map(function ($item) {
        return $item-&gt;get(&#39;foo&#39;);
    }, $items),
    function ($item) {
        return $item-&gt;bar == true;
});
</code></pre>
<p>Or, even worse, this:</p>
<pre><code class="lang-php">$result1 = array_map(function ($item) {
    return $item-&gt;get(&#39;foo&#39;);
}, $items);
$result2 = array_filter($result1, function ($item) {
    return $item-&gt;bar == true;
});
</code></pre>
<p>Into this:</p>
<pre><code class="lang-php">$result = Collection::make($items)
    -&gt;map(function ($item) {
        return $item-&gt;get(&#39;foo&#39;);
    })-&gt;filter(function ($item) {
        return $item-&gt;bar == true;
    })-&gt;toArray();
</code></pre>
<p>Much cleaner, more elegant, and far easier to understand.</p>
<p>A while back, after some frustration with PHP’s native strings, I started wondering how practical it would be to produce a string implementation that was more like the string objects in languages like Python and Javascript, with inspiration from collection implementations such as that used by Laravel. I soon discovered that it was very practical, and with a bit of work it’s not hard to produce your own, more elegant string class.</p>
<p>The most fundamental functionality required is to be able to create a string object, either by passing a string to the constructor or calling a static method. Our string class should be able to do both:</p>
<pre><code class="lang-php">&lt;?php

class Str
{
    protected $string;

    public function __construct(string $string = &#39;&#39;)
    {
        $this-&gt;string = $string;
    }

    public static function make(string $string)
    {
        return new static($string);
    }
}
</code></pre>
<h2 id="making-it-iterable">Making it iterable</h2>
<p>To be able to get the length of a string, it needs to implement the <a href="http://php.net/manual/en/class.countable.php"><code>Countable</code></a> interface:</p>
<pre><code class="lang-php">use Countable;

class Str implements Countable
{
    ...
    public function count()
    {
        return strlen($this-&gt;string);
    }
}
</code></pre>
<p>To access it as an array, it needs to implement the <a href="http://php.net/manual/en/class.arrayaccess.php"><code>ArrayAccess</code></a> interface:</p>
<pre><code class="lang-php">...
use ArrayAccess;

class Str implements Countable, ArrayAccess
{
    ...
    public function offsetExists($offset)
    {
        return isset($this-&gt;string[$offset]);
    }

    public function offsetGet($offset)
    {
        return isset($this-&gt;string[$offset]) ? $this-&gt;string[$offset] : null;
    }

    public function offsetSet($offset, $value)
    {
        if (is_null($offset)) {
            $this-&gt;string[] = $value;
        } else {
            $this-&gt;string[$offset] = $value;
        }
    }

    public function offsetUnset($offset)
    {
        $this-&gt;string = substr_replace($this-&gt;string, &#39;&#39;, $offset, 1);
    }
}
</code></pre>
<p>And to make it iterable, it needs to implement the <a href="http://php.net/manual/en/class.iterator.php"><code>Iterator</code></a> interface:</p>
<pre><code class="lang-php">use Iterator;

class Str implements Countable, ArrayAccess, Iterator
{
    ...
    public function current()
    {
        return $this-&gt;string[$this-&gt;position];
    }

    public function key()
    {
        return $this-&gt;position;
    }

    public function next()
    {
        ++$this-&gt;position;
    }

    public function rewind()
    {
        $this-&gt;position = 0;
    }

    public function valid()
    {
        return isset($this-&gt;string[$this-&gt;position]);
    }
}
</code></pre>
<h2 id="making-it-work-as-a-string">Making it work as a string</h2>
<p>To be useful, it also needs to be possible to actually use it as a string - for instance, you should be able to do this:</p>
<pre><code class="lang-php">$foo = Str::make(&#39;I am the very model of a modern major general&#39;);
echo $foo;
</code></pre>
<p>Fortunately, the <a href="http://php.net/manual/en/language.oop5.magic.php#object.tostring"><code>__toString()</code></a> magic method allows this:</p>
<pre><code class="lang-php">    public function __toString()
    {
        return $this-&gt;string;
    }
</code></pre>
<h2 id="adding-methods">Adding methods</h2>
<p>With that functionality in place, you can then start adding support for the methods you need in your string objects. If you’re looking to be able to use the same functionality as existing PHP methods, you can call those functions inside your methods. However, be sure to return a new instance of your string object from each method - that way, you can continually chain them:</p>
<pre><code class="lang-php">    public function replace($find, $replace)
    {
        return new static(str_replace($find, $replace, $this-&gt;string));
    }

    public function toUpper()
    {
        return new static(strtoupper($this-&gt;string));
    }

    public function toLower()
    {
        return new static(strtolower($this-&gt;string));
    }

    public function trim()
    {
        return new static(trim($this-&gt;string));
    }

    public function ltrim()
    {
        return new static(ltrim($this-&gt;string));
    }

    public function rtrim()
    {
        return new static(rtrim($this-&gt;string));
    }
</code></pre>
<p>Now, you can write something like this:</p>
<pre><code class="lang-php">return Str::make(&#39;I am the very model of a modern major general  &#39;)
    -&gt;trim()
    -&gt;replace(&#39;modern major general&#39;, &#39;scientist Salarian&#39;)
    -&gt;toLower();
</code></pre>
<p>While you could do this with PHP’s native string functions alone, it would be a lot less elegant. In addition, if you have other, more complex string manipulations that you often do in a particular application, it may make sense to write a method for that so that your string objects can encapsulate that functionality for easier reuse.</p>
<p>As our string objects are iterable, we can also do this:</p>
<pre><code class="lang-php">&gt;&gt;&gt; $foo = Str::make(&#39;foo&#39;);
&gt;&gt;&gt; foreach ($foo as $letter) { echo &quot;$letter\n&quot;; }
f
o
o
</code></pre>
<p>If you have an application that does some complex string manipulation, having a string utility class like this can make for much more expressive, elegant and easy-to-comprehend code than PHP’s native string functions. If you want to see a working implementation for this, check out my proof of concept collection and string utility library <a href="https://github.com/matthewbdaly/proper">Proper</a>.</p>
]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Forcing SSL in CodeIgniter]]></title>
        <id>https://matthewdaly.co.uk/blog/2018/06/23/forcing-ssl-in-codeigniter/</id>
        <link href="https://matthewdaly.co.uk/blog/2018/06/23/forcing-ssl-in-codeigniter/">
        </link>
        <updated>2018-06-23T12:03:28Z</updated>
        <summary type="html"><![CDATA[<p>I haven’t started a new CodeIgniter project since 2014, and don’t intend to, but on occasion I’ve been asked to do maintenance work on legacy CodeIgniter projects. This week I was asked to help out with a situation where a CodeIgniter site was being migrated to HTTPS and there were issues resulting from the migration.</p>
<p>Back in 2012, when working on my first solo project, I’d built a website using CodeIgniter that used HTTPS, but also needed to support an affiliate marketing system that did not support it, so certain pages had to force HTTP, and others had to force HTTPS, so I’d used the hook system to create hooks to enforce this. This kind of requirement is unlikely to reoccur now because HTTPS is becoming more prevalent, but sometimes it may be easier to enforce HTTPS at application level than in the web server configuration or using htaccess. It’s relatively straightforward to do that in CodeIgniter.</p>
<p>The first step is to create the hook. Save this as <code>application/hooks/ssl.php</code>:</p>
<pre><code class="lang-php">&lt;?php
function force_ssl()
{
    $CI =&amp; get_instance();
    $CI-&gt;config-&gt;config[&#39;base_url&#39;] = str_replace(&#39;http://&#39;, &#39;https://&#39;, $CI-&gt;config-&gt;config[&#39;base_url&#39;]);
    if ($_SERVER[&#39;SERVER_PORT&#39;] != 443) redirect($CI-&gt;uri-&gt;uri_string());
}
?&gt;
</code></pre>
<p>Next, we register the hook. Update <code>application/configs/hooks.php</code> as follows:</p>
<pre><code class="lang-php">&lt;?php  if ( ! defined(&#39;BASEPATH&#39;)) exit(&#39;No direct script access allowed&#39;);
/*
| -------------------------------------------------------------------------
| Hooks
| -------------------------------------------------------------------------
| This file lets you define &quot;hooks&quot; to extend CI without hacking the core
| files.  Please see the user guide for info:
|
|    http://codeigniter.com/user_guide/general/hooks.html
|
*/

$hook[&#39;post_controller_constructor&#39;][] = array(
                                &#39;function&#39; =&gt; &#39;force_ssl&#39;,
                                &#39;filename&#39; =&gt; &#39;ssl.php&#39;,
                                &#39;filepath&#39; =&gt; &#39;hooks&#39;
                                );

/* End of file hooks.php */
/* Location: ./application/config/hooks.php */
</code></pre>
<p>This tells CodeIgniter that it should looks in the <code>application/hooks</code> directory for a file called <code>ssl.php</code>, and return the function <code>force_ssl</code>.</p>
<p>Finally, we enable hooks. Update <code>application/config/config.php</code>:</p>
<pre><code class="lang-php">$config[&#39;enable_hooks&#39;] = TRUE;
</code></pre>
<p>If you only want to force SSL in production, not development, you may want to amend the <code>ssl.php</code> file to only perform the redirect in non-development environments, perhaps by using an environment variable via DotEnv.</p>
]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Logging to the ELK stack with Laravel]]></title>
        <id>https://matthewdaly.co.uk/blog/2018/06/03/logging-to-the-elk-stack-with-laravel/</id>
        <link href="https://matthewdaly.co.uk/blog/2018/06/03/logging-to-the-elk-stack-with-laravel/">
        </link>
        <updated>2018-06-03T15:30:54Z</updated>
        <summary type="html"><![CDATA[<p>Logging to text files is the simplest and most common logging setup for web apps, and it works fine for relatively small and simple applications. However, it does have some downsides:</p>
<ul>
<li>It’s difficult to make the log files accessible - normally users have to SSH in to read them.</li>
<li>The tools used to filter and analyse log files have a fairly high technical barrier to access - grep and sed are not exactly easy for non-programmers to pick up, so business information can be hard to get.</li>
<li>It’s hard to visually identify trends in the data.</li>
<li>Log files don’t let you know immediately when something urgent happens</li>
<li>You can’t access logs for different applications through the same interface.</li>
</ul>
<p>For rare, urgent issues where you need to be informed immediately they occur, it’s straightforward to log to an instant messaging solution such as Slack or Hipchat. However, these aren’t easily searchable, and can only be used for the most important errors (otherwise, there’s a risk that important data will be lost in the noise). There are third-party services that allow you to search and filter your logs, but they can be prohibitively expensive.</p>
<p>The <a href="https://www.elastic.co/elk-stack">ELK stack</a> has recently gained a lot of attention as a sophisticated solution for logging application data. It consists of:</p>
<ul>
<li>Logstash for processing log data</li>
<li>Elasticsearch as a searchable storage backend</li>
<li>Kibana as a web interface</li>
</ul>
<p>By making the log data available using a powerful web interface, you can easily expose it to non-technical users. Kibana also comes with powerful tools to aggregate and filter the data. In addition, you can run your own instance, giving you a greater degree of control (as well as possibly being more cost-effective) compared to using a third-party service.</p>
<p>In this post I’ll show you how to configure a Laravel application to log to an instance of the ELK stack. Fortunately, Laravel uses the popular Monolog logging library by default, which is relatively easy to get to work with the ELK stack. First, we need to install support for the GELF logging format:</p>
<pre><code class="lang-bash">$ composer require graylog2/gelf-php
</code></pre>
<p>Then, we create a custom logger class:</p>
<pre><code class="lang-php">&lt;?php

namespace App\Logging;

use Monolog\Logger;
use Monolog\Handler\GelfHandler;
use Gelf\Publisher;
use Gelf\Transport\UdpTransport;

class GelfLogger
{
    /**
     * Create a custom Monolog instance.
     *
     * @param  array  $config
     * @return \Monolog\Logger
     */
    public function __invoke(array $config)
    {
        $handler = new GelfHandler(new Publisher(new UdpTransport($config[&#39;host&#39;], $config[&#39;port&#39;])));
        return new Logger(&#39;main&#39;, [$handler]);
    }
}
</code></pre>
<p>Finally, we configure our application to use this as our custom driver and specify the host and port in <code>config/logging.php</code>:</p>
<pre><code class="lang-php">        &#39;custom&#39; =&gt; [
            &#39;driver&#39; =&gt; &#39;custom&#39;,
            &#39;via&#39; =&gt; App\Logging\GelfLogger::class,
            &#39;host&#39; =&gt; &#39;127.0.0.1&#39;,
            &#39;port&#39; =&gt; 12201,
        ],
</code></pre>
<p>You can then set up whatever logging channels you need for your application, and specify whatever log level you feel is appropriate.</p>
<p>Please note that this requires at least Laravel 5.6 - this file doesn’t exist in Laravel 5.5 and earlier, so you may have more work on your hands to integrate it with older versions.</p>
<p>If you already have an instance of the ELK stack set up on a remote server that’s already set up to accept input as GELF, then you should be able to point it at that and you’ll be ready to go. If you just want to try it out, I’ve been using a <a href="https://github.com/deviantony/docker-elk">Docker-based project</a> that makes it straightforward to run the whole stack locally. However, you will need to amend <code>logstash/pipeline/logstash.conf</code> as follows to allow it to accept log data:</p>
<pre><code class="lang-json">input {
    tcp {
        port =&gt; 5000
    }
   gelf {
       port =&gt; 12201
       type =&gt; gelf
       codec =&gt; &quot;json&quot;
   }
}

## Add your filters / logstash plugins configuration here

output {
    elasticsearch {
        hosts =&gt; &quot;elasticsearch:9200&quot;
    }
}
</code></pre>
<p>Then you can start it up using the instructions in the repository and it should be ready to go. Now, if you run the following command from Tinker:</p>
<pre><code class="lang-php">Log::info(&#39;Just testing&#39;);
</code></pre>
<p>Then if you access the web interface, you should be able to find that log message without any difficulty.</p>
<p>Now, this only covers the Laravel application logs. You may well want to pass other logs through to Logstash, such as Apache, Nginx or MySQL logs, and a quick Google should be sufficient to find ideas on how you might log for these services. Creating visualisations with Kibana is a huge subject, and the existing documentation covers that quite well, so if you’re interested in learning more about that I’d recommend reading the documentation and having a play with the dashboard.</p>
]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Full-text search with MariaDB]]></title>
        <id>https://matthewdaly.co.uk/blog/2018/05/13/full-text-search-with-mariadb/</id>
        <link href="https://matthewdaly.co.uk/blog/2018/05/13/full-text-search-with-mariadb/">
        </link>
        <updated>2018-05-13T13:55:42Z</updated>
        <summary type="html"><![CDATA[<p>Recently I had the occasion to check out MariaDB’s implementation of full-text search. As it’s a relatively recent arrival in MySQL and MariaDB, it doesn’t seem to get all that much attention. In this post I’ll show you how to use it, with a few Laravel-specific pointers. We’ll be using the default <code>User</code> model in a new Laravel installation, which has columns for <code>name</code> and <code>email</code>.</p>
<p>Our first task is to create the fulltext index, which is necessary to perform the query. Run the following command:</p>
<pre><code class="lang-sql">ALTER TABLE users ADD FULLTEXT (name, email);
</code></pre>
<p>As you can see, we can specify multiple columns in our table to index.</p>
<p>If you’re using Laravel, you’ll want to create the following migration for this:</p>
<pre><code class="lang-php">&lt;?php

use Illuminate\Support\Facades\Schema;
use Illuminate\Database\Schema\Blueprint;
use Illuminate\Database\Migrations\Migration;

class AddFulltextIndexForUsers extends Migration
{
    /**
     * Run the migrations.
     *
     * @return void
     */
    public function up()
    {
        DB::statement(&#39;ALTER TABLE users ADD FULLTEXT(name, email)&#39;);
    }

    /**
     * Reverse the migrations.
     *
     * @return void
     */
    public function down()
    {
        DB::statement(&#39;ALTER TABLE users DROP INDEX IF EXISTS name&#39;);
    }
}
</code></pre>
<p>Note that the index is named after the first field passed to it, so when we drop it we refer to it as <code>name</code>. Then, to actually query the index, you should run a command something like this:</p>
<pre><code class="lang-sql">SELECT * FROM users WHERE MATCH(name, email) AGAINST (&#39;jeff&#39; IN NATURAL LANGUAGE MODE);
</code></pre>
<p>Note that <code>NATURAL LANGUAGE MODE</code> is actually the default, so you can leave it off if you wish. We also have to specify the columns to match against.</p>
<p>If you’re using Laravel, you may want to create a reusable local scope for it:</p>
<pre><code class="lang-php">    public function scopeSearch($query, $search)
    {
        if (!$search) {
            return $query;
        }
        return $query-&gt;whereRaw(&#39;MATCH(name, email) AGAINST (?)&#39;, [$search]);
    }
</code></pre>
<p>Then you can call it as follows:</p>
<pre><code class="lang-php">User::search(&#39;jeff&#39;)-&gt;get();
</code></pre>
<p>I personally have noticed that the query using the <code>MATCH</code> keywords seems to be far more performant, with the response time being between five and ten times less than a similar command using <code>LIKE</code>, however this observation isn’t very scientific (plus, we are talking about queries that still run in a fraction of a second). However, if you’re doing a particularly expensive query that currently uses a <code>LIKE</code> statement, it’s possible you may get better results by switching to a <code>MATCH</code> statement. Full-text search probably isn’t all that useful in this context - it’s only once we’re talking about longer text, such as blog posts, that some of the advantages like support for stopwords comes into play.</p>
<p>From what I’ve seen this implementation of full-text search is a lot simpler than in PostgreSQL, which has ups and downs. On the one hand, it’s a lot easier to implement, but conversely it’s less useful - there’s no obvious way to perform a full-text search against joined tables. However, it does seem to be superior to using a <code>LIKE</code> statement, so it’s probably a good fit for smaller sites where something like Elasticsearch would be overkill.</p>
]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Building a letter classifier in PHP with Tesseract OCR and PHP ML]]></title>
        <id>https://matthewdaly.co.uk/blog/2018/05/10/building-a-letter-classifier-in-php-with-tesseract-ocr-and-php-ml/</id>
        <link href="https://matthewdaly.co.uk/blog/2018/05/10/building-a-letter-classifier-in-php-with-tesseract-ocr-and-php-ml/">
        </link>
        <updated>2018-05-10T22:50:08Z</updated>
        <summary type="html"><![CDATA[<p>PHP isn’t the first language that springs to mind when it comes to machine learning. However, it is practical to use PHP for machine learning purposes. In this tutorial I’ll show you how to build a pipeline for classifying letters.</p>
<h2 id="the-brief">The brief</h2>
<p>Before I was a web dev, I was a clerical worker for an FTSE-100 insurance company, doing a lot of work that nowadays is possible to automate away, if you know how. When they received a letter or other communication from a client, it would be sent to be scanned on. Once scanned, a human would have to look at it to classify it, eg was it a complaint, a request for information, a request for a quote, or something else, as well as assign it to a policy number. Let’s imagine we’ve been asked to build a proof of concept for automating this process. This is a good example of a real-world problem that machine learning can help with.</p>
<p>As this is a proof of concept we aren’t looking to build a web app for this - for simplicity’s sake this will be a command-line application. Unlike emails, letters don’t come in an easily machine-readable format, so we will be receiving them as PDF files (since they would have been scanned on, this is a reasonable assumption). Feel free to mock up your own example letters using your own classifications, but I will be classifying letters into four groups:</p>
<ul>
<li><strong>Complaints</strong> - letters expressing dissatisfaction</li>
<li><strong>Information requests</strong> - letters requesting general information</li>
<li><strong>Surrender quotes</strong> - letters requesting a surrender quote</li>
<li><strong>Surrender forms</strong> - letters requesting surrender forms</li>
</ul>
<p>Our application will therefore take in a PDF file at one end, and perform the following actions on it:</p>
<ul>
<li>Convert the PDF file to a PNG file</li>
<li>Use OCR (optical character recognition) to convert the letter to plain text</li>
<li>Strip out unwanted whitespace</li>
<li>Extract any visible policy number from the text</li>
<li>Use a machine learning library to classify the letter, having taught it using prior examples</li>
</ul>
<p>Sound interesting? Let’s get started…</p>
<h2 id="introducing-pipelines">Introducing pipelines</h2>
<p>As our application will be carrying out a series of discrete steps on our data, it makes sense to use the pipeline pattern for this project. Fortunately, the PHP League have produced a excellent <a href="http://pipeline.thephpleague.com/">package</a> implementing this. We can therefore create a single class for each step in the process and have it handle that in isolation.</p>
<p>We’ll also use the Symfony Console component to implement our command-line application. For our machine learning library we will be using <a href="https://php-ml.readthedocs.io/en/latest/">PHP ML</a>, which requires PHP 7.1 or greater. For OCR, we will be using <a href="https://github.com/thiagoalessio/tesseract-ocr-for-php">Tesseract</a>, so you will need to install the underlying Tesseract OCR library, as well as support for your language. On Ubuntu you can install these as follows:</p>
<pre><code class="lang-bash">$ sudo apt-get install tesseract-ocr tesseract-ocr-eng
</code></pre>
<p>This assumes you are using English, however you should be able to find packages to support many other languages. Finally, we need ImageMagick to be installed in order to convert PDF files to PNG’s.</p>
<p>Your <code>composer.json</code> should look something like this:</p>
<pre><code class="lang-json">{
    &quot;name&quot;: &quot;matthewbdaly/letter-classifier&quot;,
    &quot;description&quot;: &quot;Demo of classifying letters in PHP&quot;,
    &quot;type&quot;: &quot;project&quot;,
    &quot;require&quot;: {
        &quot;league/pipeline&quot;: &quot;^0.3.0&quot;,
        &quot;thiagoalessio/tesseract_ocr&quot;: &quot;^2.2&quot;,
        &quot;php-ai/php-ml&quot;: &quot;^0.6.2&quot;,
        &quot;symfony/console&quot;: &quot;^4.0&quot;
    },
    &quot;require-dev&quot;: {
        &quot;phpspec/phpspec&quot;: &quot;^4.3&quot;,
        &quot;psy/psysh&quot;: &quot;^0.8.17&quot;
    },
    &quot;autoload&quot;: {
        &quot;psr-4&quot;: {
            &quot;Matthewbdaly\\LetterClassifier\\&quot;: &quot;src/&quot;
        }
    },
    &quot;license&quot;: &quot;MIT&quot;,
    &quot;authors&quot;: [
        {
            &quot;name&quot;: &quot;Matthew Daly&quot;,
            &quot;email&quot;: &quot;matthewbdaly@gmail.com&quot;
        }
    ]
}
</code></pre>
<p>Next, let’s write the outline of our command-line client. We’ll load a single class for our processor command. Save this as <code>app</code>:</p>
<pre><code class="lang-php">#!/usr/bin/env php
&lt;?php

require __DIR__.&#39;/vendor/autoload.php&#39;;

use Symfony\Component\Console\Application;
use Matthewbdaly\LetterClassifier\Commands\Processor;

$application = new Application();
$application-&gt;add(new Processor());
$application-&gt;run();
</code></pre>
<p>Next, we create our command. Save this as <code>src/Commands/Processor.php</code>:</p>
<pre><code class="lang-php">&lt;?php

namespace Matthewbdaly\LetterClassifier\Commands;

use Symfony\Component\Console\Command\Command;
use Symfony\Component\Console\Input\InputInterface;
use Symfony\Component\Console\Output\OutputInterface;
use Symfony\Component\Console\Input\InputArgument;
use League\Pipeline\Pipeline;
use Matthewbdaly\LetterClassifier\Stages\ConvertPdfToPng;
use Matthewbdaly\LetterClassifier\Stages\ReadFile;
use Matthewbdaly\LetterClassifier\Stages\Classify;
use Matthewbdaly\LetterClassifier\Stages\StripTabs;
use Matthewbdaly\LetterClassifier\Stages\GetPolicyNumber;

class Processor extends Command
{
    protected function configure()
    {
        $this-&gt;setName(&#39;process&#39;)
            -&gt;setDescription(&#39;Processes a file&#39;)
            -&gt;setHelp(&#39;This command processes a file&#39;)
            -&gt;addArgument(&#39;file&#39;, InputArgument::REQUIRED, &#39;File to process&#39;);
    }

    protected function execute(InputInterface $input, OutputInterface $output)
    {
        $file = $input-&gt;getArgument(&#39;file&#39;);
        $pipeline = (new Pipeline)
            -&gt;pipe(new ConvertPdfToPng)
            -&gt;pipe(new ReadFile)
            -&gt;pipe(new StripTabs)
            -&gt;pipe(new GetPolicyNumber)
            -&gt;pipe(new Classify);
        $response = $pipeline-&gt;process($file);
        $output-&gt;writeln(&quot;Classification is &quot;.$response[&#39;classification&#39;]);
        $output-&gt;writeln(&quot;Policy number is &quot;.$response[&#39;policy&#39;]);
    }
}
</code></pre>
<p>Note how our command accepts the file name as an argument. We then instantiate our pipeline and pass it through a series of classes, each of which has a single role. Finally, we retrieve our response and output it.</p>
<p>With that done, we can move on to implementing our first step. Save this as <code>src/Stages/ConvertPdfToPng.php</code>:</p>
<pre><code class="lang-php">&lt;?php

namespace Matthewbdaly\LetterClassifier\Stages;

use Imagick;

class ConvertPdfToPng
{
    public function __invoke($file)
    {
        $tmp = tmpfile();
        $uri = stream_get_meta_data($tmp)[&#39;uri&#39;];
        $img = new Imagick();
        $img-&gt;setResolution(300, 300);
        $img-&gt;readImage($file);
        $img-&gt;setImageDepth(8);
        $img-&gt;setImageFormat(&#39;png&#39;);
        $img-&gt;writeImage($uri);
        return $tmp;
    }
}
</code></pre>
<p>This stage fetches the file passed through, and converts it into a PNG file, stores it as a temporary file, and returns a reference to it. The output of this stage will then form the input of the next. This is how pipelines work, and it makes it easy to break up a complex process into multiple steps that can be reused in different places, facilitating easier code reuse and making your code simpler to understand and reason about.</p>
<p>Our next step carries out optical character recognition. Save this as <code>src/Stages/ReadFile.php</code>:</p>
<pre><code class="lang-php">&lt;?php

namespace Matthewbdaly\LetterClassifier\Stages;

use thiagoalessio\TesseractOCR\TesseractOCR;

class ReadFile
{
    public function __invoke($file)
    {
        $uri = stream_get_meta_data($file)[&#39;uri&#39;];
        $ocr = new TesseractOCR($uri);
        return $ocr-&gt;lang(&#39;eng&#39;)-&gt;run();
    }
}
</code></pre>
<p>As you can see, this accepts the link to the temporary file as an argument, and runs Tesseract on it to retrieve the text. Note that we specify a language of <code>eng</code> - if you want to use a language other than English, you should specify it here.</p>
<p>At this point, we should have some usable text, but there may be unknown amounts of whitespace, so our next step uses a regex to strip them out. Save this as <code>src/Stages/StripTabs.php</code>:</p>
<pre><code class="lang-php">&lt;?php

namespace Matthewbdaly\LetterClassifier\Stages;

class StripTabs
{
    public function __invoke($content)
    {
        return trim(preg_replace(&#39;/\s+/&#39;, &#39; &#39;, $content));
    }
}
</code></pre>
<p>With our whitespace issue sorted out, we now need to retrieve the policy number the communication should be filed under. These are generally regular alphanumeric patterns, so regexes are a suitable way of matching them. As this is a proof of concept, we’ll assume a very simple pattern for policy numbers in that they will consist of between seven and nine digits. Save this as <code>src/Stages/GetPolicyNumber.php</code>:</p>
<pre><code class="lang-php">&lt;?php

namespace Matthewbdaly\LetterClassifier\Stages;

class GetPolicyNumber
{
    public function __invoke($content)
    {
        $matches = [];
        $policyNumber = &#39;&#39;;
        preg_match(&#39;/\d{7,9}/&#39;, $content, $matches);
        if (count($matches)) {
            $policyNumber = $matches[0];
        }
        return [
            &#39;content&#39; =&gt; $content,
            &#39;policy&#39; =&gt; $policyNumber
        ];
    }
}
</code></pre>
<p>Finally, we’re onto the really tough part - using machine learning to classify the letters. Save this as <code>src/Stages/Classify.php</code>:</p>
<pre><code class="lang-php">&lt;?php

namespace Matthewbdaly\LetterClassifier\Stages;

use Phpml\Dataset\CsvDataset;
use Phpml\Dataset\ArrayDataset;
use Phpml\FeatureExtraction\TokenCountVectorizer;
use Phpml\Tokenization\WordTokenizer;
use Phpml\CrossValidation\StratifiedRandomSplit;
use Phpml\FeatureExtraction\TfIdfTransformer;
use Phpml\Metric\Accuracy;
use Phpml\Classification\SVC;
use Phpml\SupportVectorMachine\Kernel;

class Classify
{
    protected $classifier;

    protected $vectorizer;

    protected $tfIdfTransformer;

    public function __construct()
    {
        $this-&gt;dataset = new CsvDataset(&#39;data/letters.csv&#39;, 1);
        $this-&gt;vectorizer = new TokenCountVectorizer(new WordTokenizer());
        $this-&gt;tfIdfTransformer = new TfIdfTransformer();
        $samples = [];
        foreach ($this-&gt;dataset-&gt;getSamples() as $sample) {
                $samples[] = $sample[0];
        }
        $this-&gt;vectorizer-&gt;fit($samples);
        $this-&gt;vectorizer-&gt;transform($samples);
        $this-&gt;tfIdfTransformer-&gt;fit($samples);
        $this-&gt;tfIdfTransformer-&gt;transform($samples);
        $dataset = new ArrayDataset($samples, $this-&gt;dataset-&gt;getTargets());
        $randomSplit = new StratifiedRandomSplit($dataset, 0.1);
        $this-&gt;classifier = new SVC(Kernel::RBF, 10000);
        $this-&gt;classifier-&gt;train($randomSplit-&gt;getTrainSamples(), $randomSplit-&gt;getTrainLabels());
        $predictedLabels = $this-&gt;classifier-&gt;predict($randomSplit-&gt;getTestSamples());
        echo &#39;Accuracy: &#39;.Accuracy::score($randomSplit-&gt;getTestLabels(), $predictedLabels);
    }

    public function __invoke(array $message)
    {
        $newSample = [$message[&#39;content&#39;]];
        $this-&gt;vectorizer-&gt;transform($newSample);
        $this-&gt;tfIdfTransformer-&gt;transform($newSample);
        $message[&#39;classification&#39;] = $this-&gt;classifier-&gt;predict($newSample)[0];
        return $message;
    }
}
</code></pre>
<p>In our constructor, we train up our model by passing our sample data through the following steps:</p>
<ul>
<li>First, we use the token count vectorizer to convert our samples to a vector of token counts - replacing every word with a number and keeping track of how often that word occurs.</li>
<li>Next, we use <code>TfIdfTransformer</code> to get statistics about how important a word is in a document.</li>
<li>Then we instantiate our classifier and train it on a random subset of our data.</li>
<li>Finally, we pass our message to our now-trained classifier and see what it tells us.</li>
</ul>
<p>Now, bear in mind I don’t have a background in machine learning and this is the first time I’ve done anything with machine learning, so I can’t tell you much more than that - if you want to know more I suggest you investigate on your own. In figuring this out I was helped a great deal by <a href="https://www.sitepoint.com/how-to-analyze-tweet-sentiments-with-php-machine-learning/">this article on Sitepoint</a>, so you might want to start there.</p>
<p>The finished application is <a href="https://github.com/matthewbdaly/letter-classifier">on GitHub</a>, and the repository includes a CSV file of training data, as well as the <code>examples</code> folder, which contains some example PDF files. You can run it as follows:</p>
<pre><code class="lang-bash">$ php app process examples/Quote.pdf
</code></pre>
<p>I found that once I had trained it up using the CSV data from the repository, it was around 70-80% accurate, which isn’t bad at all considering the comparatively small size of the dataset. If this were genuinely being used in production, there would be an extremely large dataset of historical scanned letters to use for training purposes, so it wouldn’t be unreasonable to expect much better results under those circumstances.</p>
<h2 id="exercises-for-the-reader">Exercises for the reader</h2>
<p>If you want to develop this concept further, here are some ideas:</p>
<ul>
<li>We should be able to correct the model when it’s wrong. Add a separate command to train the model by passing through a file and specifying how it should be categorised, eg <code>php app train File.pdf quote</code>.</li>
<li>Try processing information from different sources. For instance, you could replace the first two stages with a stage that pulls all unread emails from a specified mailbox using PHP’s IMAP support, or fetching data from the Twitter API. Or you could have a telephony service such as Twilio set up as your voicemail, and automatically transcribe them, then pass the text to PHP ML for classification.</li>
<li>If you’re multilingual, you could try adding a step to sort letters by language and have separate models for classifying in each language</li>
</ul>
<h2 id="summary">Summary</h2>
<p>It’s actually quite a sobering thought that <em>already</em> it’s possible to use techniques like these to produce tools that replace people in various jobs, and as the tooling matures more and more tasks involving classification are going to become amenable to automation using machine learning.</p>
<p>This was my first experience with machine learning and it’s been very interesting for me to solve a real-world problem with it. I hope it gives you some ideas about how you could use it too.</p>
]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Console applications with the Symfony Console component]]></title>
        <id>https://matthewdaly.co.uk/blog/2018/04/29/console-applications-with-the-symfony-console-component/</id>
        <link href="https://matthewdaly.co.uk/blog/2018/04/29/console-applications-with-the-symfony-console-component/">
        </link>
        <updated>2018-04-29T19:59:27Z</updated>
        <summary type="html"><![CDATA[<p>Recently I’ve had the occasion to add a series of console commands to a legacy application. This can be made straightforward by using the Symfony console component. In this post I’ll demonstrate how to write a simple console command for clearing a cache folder.</p>
<p>The first step is to install the Console component:</p>
<pre><code class="lang-bash">$ composer require symfony/console
</code></pre>
<p>Then we write the main script for the application. I usually save mine as <code>console</code> - note that we don’t want to have to type out a file extension, so instead we use the shebang:</p>
<pre><code class="lang-php">#!/user/bin/env php
&lt;?php

require __DIR__.&#39;/vendor/autoload.php&#39;;

use Symfony\Component\Console\Application;

define(&#39;CONSOLE_ROOT&#39;, __DIR__);
$app = new Application();

$app-&gt;run();
</code></pre>
<p>In this case, I’ve defined <code>CONSOLE_ROOT</code> as the directory in which the console command is run - that way, the commands can use it to refer to the application root.</p>
<p>We can then run our console application as follows:</p>
<pre><code class="lang-bash">$ php console
Console Tool

Usage:
  command [options] [arguments]

Options:
  -h, --help            Display this help message
  -q, --quiet           Do not output any message
  -V, --version         Display this application version
      --ansi            Force ANSI output
      --no-ansi         Disable ANSI output
  -n, --no-interaction  Do not ask any interactive question
  -v|vv|vvv, --verbose  Increase the verbosity of messages: 1 for normal output, 2 for more verbose output and 3 for debug

Available commands:
  help  Displays help for a command
  list  Lists commands
</code></pre>
<p>This displays the available commands, but you’ll note that there are none except for <code>help</code> and <code>list</code>. We’ll remedy that. First, we’ll register a command:</p>
<pre><code class="lang-php">$app-&gt;add(new App\Console\ClearCacheCommand);
</code></pre>
<p>This has to be done in <code>console</code>, after we create <code>$app</code>, but before we run it.</p>
<p>Don’t forget to update the autoload section of your <code>composer.json</code> to register the namespace:</p>
<pre><code class="lang-json">    &quot;autoload&quot;: {
        &quot;psr-4&quot;: {
            &quot;App\\Console\\&quot;: &quot;src/Console/&quot;
        }
    },
</code></pre>
<p>Then create the class for that command. This class must extend <code>Symfony\Component\Console\Command\Command</code>, and must have two methods:</p>
<ul>
<li><code>configure()</code></li>
<li><code>execute()</code></li>
</ul>
<p>In addition, the <code>execute()</code> method must accept two arguments, an instance of <code>Symfony\Component\Console\Input\InputInterface</code>, and an instance of <code>Symfony\Component\Console\Output\OutputInterface</code>. There are used to retrieve input and display output.</p>
<p>Let’s write our command:</p>
<pre><code class="lang-php">&lt;?php

namespace App\Console;

use Symfony\Component\Console\Command\Command;
use Symfony\Component\Console\Input\InputInterface;
use Symfony\Component\Console\Output\OutputInterface;

class ClearCacheCommand extends Command
{
    protected function configure()
    {
        $this-&gt;setName(&#39;cache:clear&#39;)
             -&gt;setDescription(&#39;Clears the cache&#39;)
             -&gt;setHelp(&#39;This command clears the application cache&#39;);
    }

    protected function execute(InputInterface $input, OutputInterface $output)
    {
        $dir = CONSOLE_ROOT.DIRECTORY_SEPARATOR.&#39;cache&#39;;
        $this-&gt;deleteTree($dir);
        $output-&gt;writeln(&#39;Cache cleared&#39;);
    } 

    private function deleteTree($dir)
    {
        $files = array_diff(scandir($dir), array(&#39;.&#39;,&#39;..&#39;)); 
        foreach ($files as $file) { 
            (is_dir(&quot;$dir/$file&quot;)) ? $this-&gt;deleteTree(&quot;$dir/$file&quot;) : unlink(&quot;$dir/$file&quot;); 
        } 
        return rmdir($dir); 
    }
}
</code></pre>
<p>As you can see, in the <code>configure()</code> method, we set the name, description and help text for the command.</p>
<p>The <code>execute()</code> method is where the actual work is done. In this case, we have some code that needs to be called recursively, so we have to pull it out into a private method. Once that’s done we use <code>$output-&gt;writeln()</code> to write a line to the output.</p>
<p>Now, if we run our console task, we should see our new command:</p>
<pre><code class="lang-bash">$ php console
Console Tool

Usage:
  command [options] [arguments]

Options:
  -h, --help            Display this help message
  -q, --quiet           Do not output any message
  -V, --version         Display this application version
      --ansi            Force ANSI output
      --no-ansi         Disable ANSI output
  -n, --no-interaction  Do not ask any interactive question
  -v|vv|vvv, --verbose  Increase the verbosity of messages: 1 for normal output, 2 for more verbose output and 3 for debug

Available commands:
  help         Displays help for a command
  list         Lists commands
 cache
  cache:clear  Clears the cache
</code></pre>
<p>And we can see it in action too:</p>
<pre><code class="lang-bash">$ php console cache:clear
Cache cleared
</code></pre>
<p>For commands that need to accept additional arguments, you can define them in the <code>configure()</code> method:</p>
<pre><code class="lang-php">$this-&gt;addArgument(&#39;file&#39;, InputArgument::REQUIRED, &#39;Which file do you want to delete?&#39;)
</code></pre>
<p>Then, you can access it in the <code>execute()</code> method using <code>InputInterface</code>:</p>
<pre><code class="lang-php">$file = $input-&gt;getArgument(&#39;file&#39;);
</code></pre>
<p>This tutorial is just skimming the surface of what you can do with the Symfony Console components - indeed, many other console interfaces, such as Laravel’s Artisan, are built on top of it. If you have a legacy application built in a framework that lacks any sort of console interface, such as CodeIgniter, then you can quite quickly produce basic console commands for working with that application. The <a href="https://symfony.com/doc/current/console.html">documentation is very good</a>, and with a little work you can soon have something up and running.</p>
]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rendering different views for mobile and desktop clients in Laravel]]></title>
        <id>https://matthewdaly.co.uk/blog/2018/04/22/rendering-different-views-for-mobile-and-desktop-clients-in-laravel/</id>
        <link href="https://matthewdaly.co.uk/blog/2018/04/22/rendering-different-views-for-mobile-and-desktop-clients-in-laravel/">
        </link>
        <updated>2018-04-22T22:50:10Z</updated>
        <summary type="html"><![CDATA[<p>This was a bit of a weird post to write. It started out explaining how I resolved an issue years ago on a CodeIgniter site, but amended to work for Laravel. In the process, I realised it made sense to implement it as middleware, and I ended up pulling it out into <a href="https://github.com/matthewbdaly/laravel-dynamic-serving">a package</a>. However, it’s still useful to understand the concept behind it, even if you prefer to just install the complete package, because your needs might be slightly different to mine.</p>
<p>On web development forums, it’s quite common to see variants of the following question:</p>
<blockquote>
<p>How do I redirect a user on a mobile device to a mobile version of the site?</p>
</blockquote>
<p>It’s quite surprising that this is still an issue that crops up. For many years, it’s been widely accepted that the correct solution for this problem is responsive design. However, there are ways in which this may not be adequate for certain applications. For instance, you may have an application where certain functionality only makes sense in a certain context, or your user interface may need to be optimised for specific environments.</p>
<p>The trouble is that a dedicated mobile site isn’t a good idea either. Among other things, it means that users can’t easily use the same bookmarks between desktop and mobile versions, and can result in at least some of the server-side logic being duplicated.</p>
<p>Fortunately, there is another way - <a href="https://developers.google.com/search/mobile-sites/mobile-seo/dynamic-serving">dynamic serving</a> allows you to render different content based on the user agent. You can also easily enable users to switch between desktop and mobile versions themselves if their client isn’t detected correctly or they just prefer the other one. I’ve implemented this years ago for a CodeIgniter site. Here’s how you might implement it in Laravel, although if you understand the principle behind it, it should be easy to adapt for any other framework.</p>
<p>Don’t try to implement mobile user agent detection yourself. Instead, find an implementation that’s actively maintained and install it with Composer. That way you can be reasonably sure that as new mobile devices come onto the market the package will detect them correctly as long as you keep it up to date. I would be inclined to go for <a href="https://github.com/jenssegers/agent">Agent</a>, since it has Laravel support baked in.</p>
<p>We could just use Agent to serve up different content based on the user agent. However, user agent strings are notoriously unreliable - if a new mobile device appears and it doesn’t show up correctly in Agent, users could find themselves forced to use the wrong UI. Instead, we need to check for a flag in the session that indicates if the session is mobile or not. If it’s not set, we set it based on the user agent. That way, if you need to offer functionality to override the detected session type, you can just update that session variable to correct that elsewhere in the application. I would be inclined to use a button in the footer that makes an AJAX request to toggle the flag, then reloads the page.</p>
<p>You also need to set the HTTP response header <code>Vary: User-Agent</code> to notify clients (including not only search engines, but also proxies at either end of the connection, such as Varnish or Squid) that the response will differ by user agent, in order to prevent users being served the wrong version.</p>
<p>Middleware is the obvious place to do this. Here’s a middleware that sets the session variable and the appropriate response headers:</p>
<pre><code class="lang-php">&lt;?php

namespace App\Http\Middleware;

use Closure;
use Jenssegers\Agent\Agent;
use Illuminate\Contracts\Session\Session;

class DetectMobile
{
    protected $agent;

    protected $session;

    public function __construct(Agent $agent, Session $session)
    {
        $this-&gt;agent = $agent;
        $this-&gt;session = $session;
    }

    /**
     * Handle an incoming request.
     *
     * @param  \Illuminate\Http\Request  $request
     * @param  \Closure  $next
     * @return mixed
     */
    public function handle($request, Closure $next)
    {
        if (!$this-&gt;session-&gt;exists(&#39;mobile&#39;)) {
            if ($this-&gt;agent-&gt;isMobile() || $this-&gt;agent-&gt;isTablet()) {
                $this-&gt;session-&gt;put(&#39;mobile&#39;, true);
            } else {
                $this-&gt;session-&gt;put(&#39;mobile&#39;, false);
            }
        }
        $response = $next($request);
        return $response-&gt;setVary(&#39;User-Agent&#39;);
    }
}
</code></pre>
<p>Now, you could then work with the session directly to retrieve the <code>mobile</code> flag, but as you may be working in the view, it makes sense to create helpers for this:</p>
<pre><code class="lang-php">&lt;?php

if (!function_exists(&#39;is_mobile&#39;)) {
    function is_mobile()
    {
        $session = app()-&gt;make(&#39;Illuminate\Contracts\Session\Session&#39;);
        return $session-&gt;get(&#39;mobile&#39;) == true;
    }
}

if (!function_exists(&#39;is_desktop&#39;)) {
    function is_desktop()
    {
        $session = app()-&gt;make(&#39;Illuminate\Contracts\Session\Session&#39;);
        return $session-&gt;get(&#39;mobile&#39;) == false;
    }
}
</code></pre>
<p>Now, if you want to serve up completely different views, you can use these helpers in your controllers. If you instead want to selectively show and hide parts of the UI based on the user agent, you can instead use these in the views to determine what parts of the page should be shown.</p>
<p>Agent offers more functionality than just detecting if a user agent is a mobile or desktop device, and you may find this useful as a starting point for developing middleware for detecting bots, or showing different content to users based on their device type or operating system. If you just need to detect if a user is a mobile or desktop client, this middleware should be sufficient.</p>
]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Making Wordpress less shit]]></title>
        <id>https://matthewdaly.co.uk/blog/2018/04/12/making-wordpress-less-shit/</id>
        <link href="https://matthewdaly.co.uk/blog/2018/04/12/making-wordpress-less-shit/">
        </link>
        <updated>2018-04-12T22:57:05Z</updated>
        <summary type="html"><![CDATA[<p>I’m not going to sugarcoat it. As a developer, I think Wordpress is shit, and I’m not alone in that opinion. Its code base dates from a time before many of the developments of the last few years that have hugely improved PHP as a language, as well as the surrounding ecosystem such as Composer and PSR-FIG, and it’s likely it couldn’t adopt many of those without making backward-incompatible changes that would affect its own ecosystem of plugins and themes. It actively forces you to write code that is far less elegant and efficient than what you might write with a proper framework such as Laravel, and the quality of many of the plugins and themes around is dire.</p>
<p>Unfortunately, it’s also difficult to avoid. Over a quarter of all websites run Wordpress, and most developers will have to work with it at some point in their careers. However, there are ways that you can improve your experience when working with Wordpress somewhat. In this post I’m going to share some methods you can use to make Wordpress less painful to use.</p>
<p>This isn’t a post about the obvious things like “Use the most recent version of PHP you can”, “Use SSL”, “Install this plugin”, “Use Vagrant/Lando” etc - I’m assuming you already know stuff like that for bog standard Wordpress development. Nor is it about actually developing Wordpress plugins or themes. Instead, this post is about bringing your Wordpress development workflow more into line with how you develop with MVC frameworks like Laravel, so that you have a better experience working with and maintaining Wordpress sites. We can’t solve the fundamental issues with Wordpress, but we can take some steps to make it easier to work with.</p>
<h2 id="use-bedrock">Use Bedrock</h2>
<p><a href="https://roots.io/bedrock/">Bedrock</a> is still Wordpress, but reorganized so that:</p>
<ul>
<li>The Wordpress core, plugins and themes can be managed with Composer for easier updates</li>
<li>The configuration can be done with a <code>.env</code> file that can be kept out of version control, rather than putting it in <code>wp-config.php</code></li>
<li>The web root is isolated to limit access to the files</li>
</ul>
<p>In short, it optimizes Wordpress for how modern developers work. Arguably that’s at the expense of site owners, since it makes it harder for non-developers to manage the site, however for any Wordpress site that’s sufficiently complex to need development work done that’s a trade-off worth making. I’ve been involved in projects where Wordpress got used alongside an MVC framework for some custom functionality, and in my experience it caused a world of problems when updating plugins and themes because version control would get out of sync, so moving that to use Composer to manage them instead would have been a huge win.</p>
<p>Using Bedrock means that if you have a parent theme you use all the time, or custom plugins of your own, you can install them using Composer by adding the Git repositories to your <code>composer.json</code>, making it easier to re-use functionality you’ve already developed. It also makes recovery easier in the event of the site being compromised, because the files outside the vendor directory will be in version control, and you can delete the vendor directory and re-run <code>composer install</code> to replace the rest. By comparison, with a regular Wordpress install, if it’s compromised you can’t always be certain you’ve got all of the files that have been changed. Also, keeping Wordpress up to date becomes a simple matter of running <code>composer update</code> regularly, verifying it hasn’t broken anything, and then deploying it to production.</p>
<p>Bedrock uses <a href="https://wpackagist.org/">WPackagist</a>, which regularly scans the Wordpress Subversion repository for plugins and themes, so at least for plugins and themes published on the Wordpress site, it’s easy to install them. Paid plugins may be more difficult - I’d be inclined to put those in a private Git repository and install them from there, although I’d be interested to know if anyone else uses another method for that.</p>
<h2 id="if-you-can-t-use-bedrock-use-wp-cli">If you can’t use Bedrock, use WP CLI</h2>
<p>If for any reason you can’t use Bedrock for a site, then have a look at <a href="https://wp-cli.org/">WP CLI</a>. On the server, you can use it to install and manage both plugins and themes, as well as the Wordpress core.</p>
<p>It’s arguably even more useful locally, as it can be used to generate scaffolding for plugins, themes (including child themes based on an existing theme), and components such as custom post types or taxonomies. In short, if you do any non-trivial amount of development with Wordpress you’ll probably find a use for it. Even if you can use Bedrock, you’re likely to find WP CLI handy for the scaffolding.</p>
<h2 id="upgrade-the-password-encryption">Upgrade the password encryption</h2>
<p>I said this wouldn’t be about using a particular plugin, but this one is too important. Wordpress’s password hashing still relies on MD5, which is <em>far</em> too weak to be considered safe. Unfortunately, Wordpress still supports PHP versions as old as 5.2, and until they drop it they can’t really switch to something more secure.</p>
<p><a href="https://roots.io/plugins/bcrypt-password/">wp-password-bcrypt</a> overrides the password functionality of Wordpress to use Bcrypt, which is what modern PHP applications use. As a result, the hashes are considerably stronger. Given that Wordpress is a common target for hackers, it’s prudent to ensure your website is as secure as you can possibly make it.</p>
<p>If you use Bedrock, it uses this plugin by default, so it’s already taken care of for you.</p>
<h2 id="use-a-proper-templating-system">Use a proper templating system</h2>
<p>PHP is a weird hybrid of a programming language and a templating system. As such, it’s all too easy to wind up with too much logic in your view layer, so it’s a good idea to use a proper templating system if you can. Unfortunately, Wordpress doesn’t support that out of the box.</p>
<p>However, there are some third-party solutions for this. <a href="https://roots.io/sage/">Sage</a> uses Laravel’s Blade templating system (and also comes with Webpack preconfigured), while <a href="https://www.upstatement.com/timber/">Timber</a> lets you use Twig.</p>
<h2 id="use-the-wordpress-rest-api-for-ajax-where-you-can">Use the Wordpress REST API for AJAX where you can</h2>
<p>Version 4.7 of Wordpress introduced the <a href="https://v2.wp-api.org/">Wordpress REST API</a>, allowing the data to be exposed via RESTful endpoints. As a result, it should now be possible to build more complex and powerful user interfaces for that data. For instance, if you were using Wordpress to build a site for listing items for sale, you could create a single-page web app for the front end using React.js and Redux, and use the API to submit it, then show the submitted items.</p>
<p>I’m not a fan of the idea the Wordpress developers seem to have of trying to make it some kind of all-singing, all-dancing universal platform for the web, and the REST API seems to be part of that idea, but it does make it a lot easier than it was in the past to do something a bit out of the ordinary with Wordpress. In some cases it might be worth using Wordpress as the backend for a <a href="https://en.wikipedia.org/wiki/Headless_CMS">headless CMS</a>, and the REST API makes that a practical approach. For simpler applications that just need to make a few AJAX calls, using the REST API is generally going to be more elegant and practical than any other approach to AJAX with Wordpress. It’s never going to perform as well or be as elegant as a custom-built REST API, but it’s definitely a step forward compared to the hoops you used to have to jump through to handle AJAX requests in Wordpress.</p>
<h2 id="summary">Summary</h2>
<p>Wordpress is, and will remain for the foreseeable future, a pain in the backside to develop for compared to something like Laravel, and I remain completely mystified by the number of people who seem to think it’s the greatest thing since sliced bread. However, it is possible to make things better if you know how - it’s just that some of this stuff seems to be relatively obscure. In particular, discovering Bedrock is potentially game-changing because it makes it so much easier to keep the site under version control.</p>
]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using stored procedures in your web app]]></title>
        <id>https://matthewdaly.co.uk/blog/2018/03/10/using-stored-procedures-in-your-web-app/</id>
        <link href="https://matthewdaly.co.uk/blog/2018/03/10/using-stored-procedures-in-your-web-app/">
        </link>
        <updated>2018-03-10T15:10:16Z</updated>
        <summary type="html"><![CDATA[<p>In the last few days I’ve done something I’ve never done before, namely written a stored procedure for a web app. Like most web developers, I know enough about SQL to be able to formulate some fairly complex queries, but I hadn’t really touched on control flow functions or stored procedures, and in my experience they tend to be the province of the dedicated database administrator, not us web devs, who will typically delegate more complex functionality to our application code.</p>
<p>In this case, there were a number of factors influencing my decision to use a stored procedure for this:</p>
<ul>
<li>The application was a legacy application which had been worked on by developers of, shall we say, varying skill levels. As a result the database schema was badly designed, with no prospect of changing it without causing huge numbers of breakages</li>
<li>The query in question was used to generate a complex report that was quite time-consuming, therefore the optimisations from using a stored procedure were worthwhile.</li>
<li>The report required that data be grouped by a set of categories which were stored in a separate table, which meant the table had to be pivoted (transformed from rows to columns), resulting in an incredibly complex dynamic query that had to be constructed on the fly by concatenating different SQL strings. In PostgreSQL, this can be done fairly easily using the <code>crosstab</code> function, but MySQL doesn’t have native support for anything like this.</li>
</ul>
<p>Historically, one issue with using stored procedures has been that it kept business logic out of the application code, meaning they are not stored in version control. However, most modern frameworks provide some support for migrations, and since they are intended to be used to make changes to the database, they are the obvious place to define the stored procedure. This particular application was built with an older framework that didn’t come with migrations, so we’d installed <a href="https://phinx.org/">Phinx</a> to handle those for us. Initially, I defined the stored procedure inside a migration that ran a raw query to create the stored procedure, as in this example:</p>
<pre><code class="lang-php">public function up()
{
   $query = &lt;&lt;&lt;EOF
CREATE PROCEDURE IF NOT EXISTS foo
BEGIN
   SELECT * FROM foo;
END
EOF;
   $this-&gt;execute($query);
}

public function down()
{
   $this-&gt;execute(&#39;DROP PROCEDURE IF EXISTS foo&#39;);
}
</code></pre>
<p>Once this is done, you can then use your framework’s particular support for raw queries to call <code>CALL foo()</code> whenever your stored procedure needs to be executed.</p>
<p>However, we soon ran into an issue. It turns out <code>mysqldump</code> doesn’t export stored procedures by default, so there was a risk that anyone working on the code base might import the database from an SQL file and not get the migrations. I’d used the Symfony Console component to create a simple command-line tool, reminiscent of Laravel’s Artisan, so I used that to create a command to set up the stored procedure, amended the migration to call that command, and placed a check in the application where the procedure was called so that if it was not defined the command would be called and the procedure would be created. In most cases this wouldn’t be an issue.</p>
<p>Having now had experience using stored procedures in a web application, there are a number of issues they raise:</p>
<ul>
<li>It’s hard to make queries flexible, whereas with something like Eloquent it’s straightforward to conditionally apply <code>WHERE</code> statements.</li>
<li>While storing them in migrations is a practical solution, if the database is likely to be imported rather than created from scratch during development it can be problematic.</li>
<li>They aren’t easily portable, not just between database management systems, but between different versions - the production server was using an older version of MySQL, and it failed to create the procedure. It’s therefore good practice for your migrations to check the procedure was created successfully and raise a noisy exception if they failed.</li>
</ul>
<p>Conversely, they do bring certain benefits:</p>
<ul>
<li>For particularly complex transactions that don’t change, such as generating reports, they are a good fit since they reduce the amount of data that needs to be sent to the database and allow the query to be pre-optimised somewhat.</li>
<li>If a particular query is unusually expensive, is called often, and can’t be cached, it may improve performance to make it a stored procedure.</li>
<li>Doing a query in a for loop is usually a very big no-no. However, if there really is no way to avoid it (and this should almost never happen), it would make sense to try to do it in a stored procedure using SQL rather than in application code since that would minimise the overhead.</li>
<li>If multiple applications need to work with the same database, using stored procedures for queries in more than one application removes the need to reimplement or copy over the code for the query in the second application - they can just call the same procedure, and if it needs to be changed it need only be done once.</li>
</ul>
<p>Honestly, I’m not sure I’m ever likely to again come across a scenario where using a stored procedure in a web application would be beneficial, but it’s been very interesting delving into aspects of SQL that I don’t normally touch on and I’ve picked up on some rarely-used SQL statements that I haven’t used before, such as <code>GROUP_CONCAT()</code> and <code>CASE</code>. With the widespread adoption of migrations in most frameworks, I think that the argument that using stored procedures keeps application logic out of version control no longer holds any water, since developers can generally be trusted to store changes to database structure in their migrations and not start messing them around, so the same applies for stored procedures. Report generation seems to be the ideal use case since this invariably involves complex queries that run regularly and don’t change often, and this is where I expect it would be most likely I’d have cause to use them again.</p>
]]></summary>
    </entry>
</feed>